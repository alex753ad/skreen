"""
Pairs Position Monitor v5.3
v5.3: Hurst warning fix (threshold 0.48), full open positions CSV
v5.2: Full Open Pos CSV, adaptive stop, MTF sync

Ğ—Ğ°Ğ¿ÑƒÑĞº: streamlit run pairs_position_monitor.py
"""

import streamlit as st
import pandas as pd
import numpy as np
import ccxt
import time
import json
import os
# v27: Unified config
try:
    from config_loader import CFG
except ImportError:
    def CFG(section, key=None, default=None):
        _d = {'strategy': {'entry_z': 1.8, 'exit_z': 0.8, 'stop_z_offset': 2.0,
              'min_stop_z': 4.0, 'max_hold_hours': 72, 'commission_pct': 0.10},
              'monitor': {'refresh_interval_sec': 120, 'exit_z_target': 0.5,
              'pnl_stop_pct': -5.0, 'hurst_critical': 0.50, 'hurst_warning': 0.48,
              'hurst_border': 0.45, 'pvalue_warning': 0.10, 'correlation_warning': 0.20,
              'trailing_z_bounce': 0.8, 'time_warning_ratio': 1.0,
              'time_exit_ratio': 1.5, 'time_critical_ratio': 2.0,
              'overshoot_deep_z': 1.0, 'pnl_trailing_threshold': 0.5,
              'pnl_trailing_fraction': 0.4}}
        if key is None:
            return _d.get(section, {})
        return _d.get(section, {}).get(key, default)
from datetime import datetime, timedelta, timezone

MSK = timezone(timedelta(hours=3))
def now_msk():
    return datetime.now(MSK)
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from statsmodels.tsa.stattools import coint

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DRY: Import shared utilities from analysis module
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
try:
    from mean_reversion_analysis import (
        calculate_hurst_exponent,
        calculate_hurst_ema,
        calculate_adaptive_robust_zscore,
        calculate_garch_zscore,
        calc_halflife_from_spread,
        assess_entry_readiness,
        check_pnl_z_disagreement,
        smart_exit_analysis,
        z_velocity_analysis,
    )
    _USE_MRA = True
except ImportError:
    _USE_MRA = False

# v5.3: assess_entry_readiness â€” imported from analysis module when available
# Local fallback always defined (used when analysis module unavailable)

def assess_entry_readiness(p):
    """
    v8.0: Ğ•Ğ´Ğ¸Ğ½Ğ°Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ° Ñ HARD HURST GATE.
    Hurst â‰¥ 0.45 â†’ max Ğ£Ğ¡Ğ›ĞĞ’ĞĞ. Hurst=0.500 fallback â†’ max Ğ¡Ğ›ĞĞ‘Ğ«Ğ™.
    """
    mandatory = [
        ('Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ â‰¥ READY', p.get('signal', 'NEUTRAL') in ('SIGNAL', 'READY'), p.get('signal', 'NEUTRAL')),
        ('|Z| â‰¥ Thr', abs(p.get('zscore', 0)) >= p.get('threshold', 2.0),
         f"|{p.get('zscore',0):.2f}| vs {p.get('threshold',2.0)}"),
        ('Q â‰¥ 50', p.get('quality_score', 0) >= 50, f"Q={p.get('quality_score', 0)}"),
        ('Dir â‰  NONE', p.get('direction', 'NONE') != 'NONE', p.get('direction', 'NONE')),
    ]
    all_mandatory = all(m[1] for m in mandatory)
    
    fdr_ok = p.get('fdr_passed', False)
    stab_ok = p.get('stability_passed', 0) >= 3
    hurst_val = p.get('hurst', 0.5)
    hurst_ok = hurst_val < 0.35
    hurst_is_fallback = hurst_val == 0.5
    
    optional = [
        ('FDR âœ…', fdr_ok, 'âœ…' if fdr_ok else 'âŒ'),
        ('Conf=HIGH', p.get('confidence', 'LOW') == 'HIGH', p.get('confidence', 'LOW')),
        ('S â‰¥ 60', p.get('signal_score', 0) >= 60, f"S={p.get('signal_score', 0)}"),
        ('Ï â‰¥ 0.5', p.get('correlation', 0) >= 0.5, f"Ï={p.get('correlation', 0):.2f}"),
        ('Stab â‰¥ 3/4', stab_ok, f"{p.get('stability_passed',0)}/{p.get('stability_total',4)}"),
        ('Hurst < 0.35', hurst_ok, f"H={hurst_val:.3f}"),
    ]
    opt_count = sum(1 for _, met, _ in optional if met)
    fdr_bypass = (not fdr_ok and p.get('quality_score', 0) >= 70 and
                  stab_ok and p.get('adf_passed', False) and hurst_ok)
    
    if all_mandatory:
        if hurst_is_fallback:
            level, label = 'CONDITIONAL', 'ğŸŸ¡ Ğ¡Ğ›ĞĞ‘Ğ«Ğ™ âš ï¸H=0.5'
        elif hurst_val >= 0.45:
            level, label = 'CONDITIONAL', 'ğŸŸ¡ Ğ£Ğ¡Ğ›ĞĞ’ĞĞ âš ï¸Hâ‰¥0.45'
        elif opt_count >= 4:
            level, label = 'ENTRY', 'ğŸŸ¢ Ğ’Ğ¥ĞĞ”'
        elif opt_count >= 2 or fdr_bypass:
            level, label = 'CONDITIONAL', 'ğŸŸ¡ Ğ£Ğ¡Ğ›ĞĞ’ĞĞ'
        else:
            level, label = 'CONDITIONAL', 'ğŸŸ¡ Ğ¡Ğ›ĞĞ‘Ğ«Ğ™'
    else:
        level, label = 'WAIT', 'âšª Ğ–Ğ”ĞĞ¢Ğ¬'
    
    return {'level': level, 'label': label, 'all_mandatory': all_mandatory,
            'mandatory': mandatory, 'optional': optional,
            'fdr_bypass': fdr_bypass, 'opt_count': opt_count}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CORE MATH (standalone â€” Ğ½Ğµ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ñ‚ Ğ¾Ñ‚ analysis module)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def kalman_hr(s1, s2, delta=1e-4, ve=1e-3):
    s1, s2 = np.array(s1, float), np.array(s2, float)
    n = min(len(s1), len(s2))
    if n < 10: return None
    s1, s2 = s1[:n], s2[:n]
    init_n = min(30, n // 3)
    try:
        X = np.column_stack([np.ones(init_n), s2[:init_n]])
        beta = np.linalg.lstsq(X, s1[:init_n], rcond=None)[0]
    except: beta = np.array([0.0, 1.0])
    P = np.eye(2); Q = np.eye(2) * delta; R = ve
    hrs, ints, spread = np.zeros(n), np.zeros(n), np.zeros(n)
    for t in range(n):
        x = np.array([1.0, s2[t]]); P += Q
        e = s1[t] - x @ beta; S = x @ P @ x + R
        K = P @ x / S; beta += K * e
        P -= np.outer(K, x) @ P; P = (P + P.T) / 2
        np.fill_diagonal(P, np.maximum(np.diag(P), 1e-10))
        hrs[t], ints[t] = beta[1], beta[0]
        spread[t] = s1[t] - beta[1] * s2[t] - beta[0]
    return {'hrs': hrs, 'intercepts': ints, 'spread': spread,
            'hr': float(hrs[-1]), 'intercept': float(ints[-1])}


def calc_zscore(spread, halflife_bars=None, min_w=10, max_w=60):
    spread = np.array(spread, float); n = len(spread)
    if halflife_bars and not np.isinf(halflife_bars) and halflife_bars > 0:
        w = int(np.clip(2.5 * halflife_bars, min_w, max_w))
    else: w = 30
    w = min(w, max(10, n // 2))
    zs = np.full(n, np.nan)
    for i in range(w, n):
        lb = spread[i - w:i]; med = np.median(lb)
        mad = np.median(np.abs(lb - med)) * 1.4826
        if mad < 1e-10:
            s = np.std(lb)
            zs[i] = (spread[i] - np.mean(lb)) / s if s > 1e-10 else 0
        else: zs[i] = (spread[i] - med) / mad
    return zs, w


def calc_halflife(spread, dt=None):
    """OU halflife Ñ‡ĞµÑ€ĞµĞ· Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ñ. dt=1/24 Ğ´Ğ»Ñ 1h, 1/6 Ğ´Ğ»Ñ 4h, 1 Ğ´Ğ»Ñ 1d."""
    s = np.array(spread, float)
    if len(s) < 20: return 999
    sl, sd = s[:-1], np.diff(s)
    n = len(sl)
    sx, sy = np.sum(sl), np.sum(sd)
    sxy, sx2 = np.sum(sl * sd), np.sum(sl**2)
    denom = n * sx2 - sx**2
    if abs(denom) < 1e-10: return 999
    b = (n * sxy - sx * sy) / denom
    if dt is None: dt = 1.0
    theta = max(0.001, min(10.0, -b / dt))
    hl = np.log(2) / theta  # Ğ² ĞµĞ´Ğ¸Ğ½Ğ¸Ñ†Ğ°Ñ… dt
    return float(hl) if hl < 999 else 999


def calc_hurst(series, min_window=8):
    """DFA Hurst exponent (ÑƒĞ¿Ñ€Ğ¾Ñ‰Ñ‘Ğ½Ğ½Ñ‹Ğ¹, ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ñ‹Ğ¹ Ñ ÑĞºĞ°Ğ½ĞµÑ€Ğ¾Ğ¼)."""
    x = np.array(series, float)
    x = x[~np.isnan(x)]
    n = len(x)
    if n < 50: return 0.5
    
    y = np.cumsum(x - np.mean(x))
    
    scales = []
    flucts = []
    min_seg = max(min_window, 4)
    max_seg = n // 4
    
    for seg_len in range(min_seg, max_seg + 1, max(1, (max_seg - min_seg) // 20)):
        n_segs = n // seg_len
        if n_segs < 2: continue
        f2_list = []
        for i in range(n_segs):
            seg = y[i * seg_len:(i + 1) * seg_len]
            t = np.arange(len(seg))
            if len(seg) < 2: continue
            coeffs = np.polyfit(t, seg, 1)
            trend = np.polyval(coeffs, t)
            f2_list.append(np.mean((seg - trend) ** 2))
        if f2_list:
            scales.append(seg_len)
            flucts.append(np.sqrt(np.mean(f2_list)))
    
    if len(scales) < 4: return 0.5
    
    log_s = np.log(scales)
    log_f = np.log(np.array(flucts) + 1e-10)
    coeffs = np.polyfit(log_s, log_f, 1)
    
    # RÂ² check
    pred = np.polyval(coeffs, log_s)
    ss_res = np.sum((log_f - pred) ** 2)
    ss_tot = np.sum((log_f - np.mean(log_f)) ** 2)
    r_sq = 1 - ss_res / ss_tot if ss_tot > 0 else 0
    
    if r_sq < 0.8: return 0.5  # fallback
    return float(np.clip(coeffs[0], 0.01, 0.99))


def calc_correlation(p1, p2, window=60):
    """Rolling ĞºĞ¾Ñ€Ñ€ĞµĞ»ÑÑ†Ğ¸Ñ."""
    n = min(len(p1), len(p2))
    if n < window: return 0.0
    r1 = np.diff(np.log(p1[-n:] + 1e-10))
    r2 = np.diff(np.log(p2[-n:] + 1e-10))
    if len(r1) < 10: return 0.0
    return float(np.corrcoef(r1[-window:], r2[-window:])[0, 1])


def calc_cointegration_pvalue(p1, p2):
    """P-value ĞºĞ¾Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ğ¸."""
    try:
        _, pval, _ = coint(p1, p2)
        return float(pval)
    except:
        return 1.0


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# POSITIONS FILE (JSON persistence)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
POSITIONS_FILE = "positions.json"

def load_positions():
    if os.path.exists(POSITIONS_FILE):
        with open(POSITIONS_FILE) as f:
            return json.load(f)
    return []

def save_positions(positions):
    with open(POSITIONS_FILE, 'w') as f:
        json.dump(positions, f, indent=2, default=str)


def add_position(coin1, coin2, direction, entry_z, entry_hr, 
                 entry_price1, entry_price2, timeframe, notes="",
                 max_hold_hours=None, pnl_stop_pct=None):
    positions = load_positions()
    # v27: defaults from unified config
    if max_hold_hours is None:
        max_hold_hours = CFG('strategy', 'max_hold_hours', 72)
    if pnl_stop_pct is None:
        pnl_stop_pct = CFG('monitor', 'pnl_stop_pct', -5.0)
    # v5.0: Adaptive stop_z â€” at least offset Z-units beyond entry
    _stop_offset = CFG('strategy', 'stop_z_offset', 2.0)
    _min_stop = CFG('strategy', 'min_stop_z', 4.0)
    adaptive_stop = max(abs(entry_z) + _stop_offset, _min_stop)
    pos = {
        'id': len(positions) + 1,
        'coin1': coin1, 'coin2': coin2,
        'direction': direction,
        'entry_z': entry_z,
        'entry_hr': entry_hr,
        'entry_price1': entry_price1,
        'entry_price2': entry_price2,
        'entry_time': now_msk().isoformat(),
        'timeframe': timeframe,
        'status': 'OPEN',
        'notes': notes,
        'exit_z_target': CFG('monitor', 'exit_z_target', 0.5),
        'stop_z': adaptive_stop,
        'max_hold_hours': max_hold_hours,
        'pnl_stop_pct': pnl_stop_pct,
    }
    positions.append(pos)
    save_positions(positions)
    return pos


def close_position(pos_id, exit_price1, exit_price2, exit_z, reason):
    positions = load_positions()
    closed_pos = None
    for p in positions:
        if p['id'] == pos_id and p['status'] == 'OPEN':
            p['status'] = 'CLOSED'
            p['exit_price1'] = exit_price1
            p['exit_price2'] = exit_price2
            p['exit_z'] = exit_z
            p['exit_time'] = now_msk().isoformat()
            p['exit_reason'] = reason
            # P&L
            r1 = (exit_price1 - p['entry_price1']) / p['entry_price1']
            r2 = (exit_price2 - p['entry_price2']) / p['entry_price2']
            hr = p['entry_hr']
            if p['direction'] == 'LONG':
                raw = r1 - hr * r2
            else:
                raw = -r1 + hr * r2
            p['pnl_pct'] = round(raw / (1 + abs(hr)) * 100, 3)
            closed_pos = p.copy()
            break
    save_positions(positions)
    
    # v25: R8 Performance Tracker â€” save to persistent history
    if closed_pos:
        try:
            save_trade_to_history(closed_pos)
        except Exception:
            pass
        # v27: Update pair memory
        try:
            from config_loader import pair_memory_update
            _pair = f"{closed_pos['coin1']}/{closed_pos['coin2']}"
            _entry_dt = closed_pos.get('entry_time', '')
            _exit_dt = closed_pos.get('exit_time', '')
            try:
                from datetime import datetime
                _et = datetime.fromisoformat(str(_entry_dt))
                _xt = datetime.fromisoformat(str(_exit_dt))
                _hold_h = (_xt - _et).total_seconds() / 3600
            except Exception:
                _hold_h = 0
            pair_memory_update(
                _pair, closed_pos.get('pnl_pct', 0), _hold_h,
                closed_pos.get('direction', ''), 
                closed_pos.get('entry_z', 0),
                closed_pos.get('exit_z', 0)
            )
        except Exception:
            pass


def save_trade_to_history(trade):
    """R8: Save closed trade to persistent CSV history."""
    import csv
    history_file = "trade_history.csv"
    fields = [
        'id', 'pair', 'coin1', 'coin2', 'direction', 'timeframe',
        'entry_z', 'exit_z', 'entry_hr', 'pnl_pct',
        'entry_time', 'exit_time', 'exit_reason',
        'entry_price1', 'entry_price2', 'exit_price1', 'exit_price2',
        'notes', 'best_pnl',
    ]
    
    row = {
        'id': trade.get('id', 0),
        'pair': f"{trade.get('coin1', '')}/{trade.get('coin2', '')}",
        'coin1': trade.get('coin1', ''),
        'coin2': trade.get('coin2', ''),
        'direction': trade.get('direction', ''),
        'timeframe': trade.get('timeframe', '4h'),
        'entry_z': trade.get('entry_z', 0),
        'exit_z': trade.get('exit_z', 0),
        'entry_hr': trade.get('entry_hr', 0),
        'pnl_pct': trade.get('pnl_pct', 0),
        'entry_time': trade.get('entry_time', ''),
        'exit_time': trade.get('exit_time', ''),
        'exit_reason': trade.get('exit_reason', ''),
        'entry_price1': trade.get('entry_price1', 0),
        'entry_price2': trade.get('entry_price2', 0),
        'exit_price1': trade.get('exit_price1', 0),
        'exit_price2': trade.get('exit_price2', 0),
        'notes': trade.get('notes', ''),
        'best_pnl': trade.get('best_pnl', 0),
    }
    
    file_exists = os.path.exists(history_file)
    with open(history_file, 'a', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=fields)
        if not file_exists:
            writer.writeheader()
        writer.writerow(row)


def load_trade_history():
    """R8: Load all trade history."""
    import csv
    history_file = "trade_history.csv"
    if not os.path.exists(history_file):
        return []
    
    with open(history_file, 'r') as f:
        reader = csv.DictReader(f)
        trades = []
        for row in reader:
            # Convert numeric fields
            for k in ['entry_z', 'exit_z', 'entry_hr', 'pnl_pct', 
                       'entry_price1', 'entry_price2', 'exit_price1', 'exit_price2', 'best_pnl']:
                try:
                    row[k] = float(row.get(k, 0) or 0)
                except (ValueError, TypeError):
                    row[k] = 0
            try:
                row['id'] = int(row.get('id', 0) or 0)
            except:
                row['id'] = 0
            trades.append(row)
    return trades


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DATA FETCHING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# v4.0: Exchange fallback chain (Binance/Bybit block cloud servers)
EXCHANGE_FALLBACK = ['okx', 'kucoin', 'bybit', 'binance']

def _get_exchange(exchange_name):
    """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ñ€Ğ°Ğ±Ğ¾Ñ‡ÑƒÑ Ğ±Ğ¸Ñ€Ğ¶Ñƒ Ñ fallback."""
    tried = set()
    chain = [exchange_name] + [e for e in EXCHANGE_FALLBACK if e != exchange_name]
    for exch in chain:
        if exch in tried: continue
        tried.add(exch)
        try:
            ex = getattr(ccxt, exch)({'enableRateLimit': True})
            ex.load_markets()
            return ex, exch
        except:
            continue
    return None, None


@st.cache_data(ttl=120)
def fetch_prices(exchange_name, coin, timeframe, lookback_bars=300):
    """v27: Fetch with retry + futures first."""
    import ccxt as _ccxt
    # Try futures first, then spot
    symbols = [f"{coin}/USDT:USDT", f"{coin}/USDT"]
    for symbol in symbols:
        for _attempt in range(3):
            try:
                ex, actual = _get_exchange(exchange_name)
                if ex is None: return None
                ohlcv = ex.fetch_ohlcv(symbol, timeframe, limit=lookback_bars)
                df = pd.DataFrame(ohlcv, columns=['ts', 'o', 'h', 'l', 'c', 'v'])
                df['ts'] = pd.to_datetime(df['ts'], unit='ms')
                return df
            except (_ccxt.NetworkError, _ccxt.RequestTimeout, _ccxt.ExchangeNotAvailable):
                time.sleep([2, 5, 15][_attempt])
            except:
                break  # try next symbol
    return None


def get_current_price(exchange_name, coin):
    """v27: Get price with retry + futures."""
    import ccxt as _ccxt
    symbols = [f"{coin}/USDT:USDT", f"{coin}/USDT"]
    for symbol in symbols:
        for _attempt in range(3):
            try:
                ex, actual = _get_exchange(exchange_name)
                if ex is None: return None
                ticker = ex.fetch_ticker(symbol)
                return ticker['last']
            except (_ccxt.NetworkError, _ccxt.RequestTimeout, _ccxt.ExchangeNotAvailable):
                time.sleep([2, 5, 15][_attempt])
            except:
                break
    return None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MONITOR LOGIC
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def monitor_position(pos, exchange_name):
    """ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ v3.0 â€” Ñ quality metrics."""
    c1, c2 = pos['coin1'], pos['coin2']
    tf = pos['timeframe']
    
    bars_map = {'1h': 300, '4h': 300, '1d': 120}
    n_bars = bars_map.get(tf, 300)
    
    df1 = fetch_prices(exchange_name, c1, tf, n_bars)
    df2 = fetch_prices(exchange_name, c2, tf, n_bars)
    
    if df1 is None or df2 is None:
        return None
    
    # Align timestamps
    merged = pd.merge(df1[['ts', 'c']], df2[['ts', 'c']], on='ts', suffixes=('_1', '_2'))
    if len(merged) < 50:
        return None
    
    p1 = merged['c_1'].values
    p2 = merged['c_2'].values
    ts = merged['ts'].tolist()
    
    # Kalman
    kf = kalman_hr(p1, p2)
    if kf is None:
        return None
    
    spread = kf['spread']
    hr_current = kf['hr']
    
    # v3.0: OU Half-life (dt-correct, ĞºĞ°Ğº Ğ² ÑĞºĞ°Ğ½ĞµÑ€Ğµ)
    dt_ou = {'1h': 1/24, '4h': 1/6, '1d': 1.0}.get(tf, 1/6)
    hpb = {'1h': 1, '4h': 4, '1d': 24}.get(tf, 4)
    
    # v18: Use SAME halflife function as scanner (critical for Z-window sync)
    if _USE_MRA:
        hl_days = calc_halflife_from_spread(spread, dt=dt_ou)
    else:
        hl_days = calc_halflife(spread, dt=dt_ou)
    hl_hours = hl_days * 24 if hl_days < 999 else 999
    hl_bars = (hl_hours / hpb) if hl_hours < 999 else None
    
    # v15: Use SAME Z-score function as scanner for consistency
    if _USE_MRA:
        z_now, zs, zw = calculate_adaptive_robust_zscore(spread, halflife_bars=hl_bars)
        # v18: GARCH Z for false convergence detection
        garch_info = calculate_garch_zscore(spread, halflife_bars=hl_bars)
        z_garch = garch_info.get('z_garch', z_now)
        garch_vol_ratio = garch_info.get('vol_ratio', 1.0)
        garch_var_expanding = garch_info.get('variance_expanding', False)
    else:
        zs, zw = calc_zscore(spread, halflife_bars=hl_bars)
        z_now = float(zs[~np.isnan(zs)][-1]) if any(~np.isnan(zs)) else 0
        z_garch = z_now
        garch_vol_ratio = 1.0
        garch_var_expanding = False
    
    # v3.0: Quality metrics (ĞºĞ°Ğº Ğ² ÑĞºĞ°Ğ½ĞµÑ€Ğµ)
    # v14: CRITICAL FIX â€” use SAME Hurst as scanner (DFA on increments)
    # v16: Hurst EMA smoothing
    if _USE_MRA:
        hurst_ema_info = calculate_hurst_ema(spread)
        hurst = hurst_ema_info.get('hurst_ema', 0.5)  # Use EMA, not raw
        hurst_raw = hurst_ema_info.get('hurst_raw', hurst)
        hurst_std = hurst_ema_info.get('hurst_std', 0)
    else:
        hurst = calc_hurst(spread)  # fallback
        hurst_raw = hurst
        hurst_std = 0
    corr = calc_correlation(p1, p2, window=min(60, len(p1) // 3))
    pvalue = calc_cointegration_pvalue(p1, p2)
    
    # v3.0: Entry readiness data
    quality_data = {
        'signal': 'SIGNAL' if abs(z_now) >= 2.0 else ('READY' if abs(z_now) >= 1.5 else 'NEUTRAL'),
        'zscore': z_now,
        'threshold': 2.0,
        'quality_score': max(0, int(100 - pvalue * 200 - max(0, hurst - 0.35) * 200)),
        'direction': pos['direction'],
        'fdr_passed': pvalue < 0.01,
        'confidence': 'HIGH' if (hurst < 0.4 and pvalue < 0.03) else ('MEDIUM' if pvalue < 0.05 else 'LOW'),
        'signal_score': max(0, int(abs(z_now) / 2.0 * 50 + (0.5 - hurst) * 100)),
        'correlation': corr,
        'stability_passed': 3 if pvalue < 0.05 else 1,
        'stability_total': 4,
        'hurst': hurst,
        'adf_passed': pvalue < 0.05,
    }
    
    # P&L (v4.0: price-based + spread-based + disagreement warning)
    r1 = (p1[-1] - pos['entry_price1']) / pos['entry_price1']
    r2 = (p2[-1] - pos['entry_price2']) / pos['entry_price2']
    hr = pos['entry_hr']
    if pos['direction'] == 'LONG':
        raw_pnl = r1 - hr * r2
    else:
        raw_pnl = -r1 + hr * r2
    pnl_pct = raw_pnl / (1 + abs(hr)) * 100
    
    # v4.0: Spread-based P&L (Ñ„Ğ¸ĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ HR Ğ¾Ñ‚ Ğ²Ñ…Ğ¾Ğ´Ğ°)
    entry_spread_val = pos['entry_price1'] - hr * pos['entry_price2']
    current_spread_val = p1[-1] - hr * p2[-1]
    spread_change = current_spread_val - entry_spread_val
    if pos['direction'] == 'LONG':
        spread_direction = 'profit' if spread_change > 0 else 'loss'
    else:
        spread_direction = 'profit' if spread_change < 0 else 'loss'
    
    # v4.0: Z-direction check
    z_entry = pos['entry_z']
    # v22: Directional Z check (fixes SOL/OKSOL false disagree on overshoot)
    # OLD: z_towards_zero = abs(z_now) < abs(z_entry) â€” WRONG for overshoot!
    # NEW: Check if Z moved in the CORRECT direction for our trade
    if pos['direction'] == 'LONG':
        # LONG entered at Z<0, wants Z to go UP (toward 0 and beyond)
        z_towards_zero = z_now > z_entry
    else:
        # SHORT entered at Z>0, wants Z to go DOWN (toward 0 and beyond)
        z_towards_zero = z_now < z_entry
    
    # v4.0: ĞŸÑ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¸ Ñ€Ğ°ÑÑ…Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ğ¸ P&L Ğ¸ Z-Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ
    # v14: Enhanced with variance collapse detection (Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğµ #1)
    pnl_z_disagree = False
    pnl_z_warning = ""
    
    # Use shared function if available
    if _USE_MRA:
        disagree_info = check_pnl_z_disagreement(z_entry, z_now, pnl_pct, pos['direction'])
        if disagree_info.get('disagreement'):
            pnl_z_disagree = True
            pnl_z_warning = disagree_info.get('warning', '')
    
    # Legacy checks (still useful as fallback)
    if not pnl_z_disagree:
        if pnl_pct > 0 and not z_towards_zero:
            pnl_z_disagree = True
            pnl_z_warning = (
                f"âš ï¸ P&L Ğ¿Ğ¾Ğ»Ğ¾Ğ¶Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ (+{pnl_pct:.2f}%), Ğ½Ğ¾ Z ÑƒÑˆÑ‘Ğ» Ğ´Ğ°Ğ»ÑŒÑˆĞµ Ğ¾Ñ‚ Ğ½ÑƒĞ»Ñ "
                f"({z_entry:+.2f} â†’ {z_now:+.2f}). "
                f"HR Ğ¸Ğ·Ğ¼ĞµĞ½Ğ¸Ğ»ÑÑ ({pos['entry_hr']:.4f} â†’ {hr_current:.4f})."
            )
        elif pnl_pct < -0.5 and z_towards_zero:
            pnl_z_disagree = True
            pnl_z_warning = (
                f"âš ï¸ Z â†’ 0 ({z_entry:+.2f} â†’ {z_now:+.2f}), Ğ½Ğ¾ P&L={pnl_pct:+.2f}%. "
                f"Ğ’Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ»Ğ¾Ğ¶Ğ½Ğ¾Ğµ ÑÑ…Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ğµ (Ïƒ ÑĞ¿Ñ€ĞµĞ´Ğ° Ğ²Ñ‹Ñ€Ğ¾ÑĞ»Ğ°)."
            )
    
    # Time in trade (Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ Ğ”Ğ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ)
    entry_dt = datetime.fromisoformat(pos['entry_time'])
    if entry_dt.tzinfo is None:
        entry_dt = entry_dt.replace(tzinfo=MSK)  # assume MSK if no tz
    hours_in = (now_msk() - entry_dt).total_seconds() / 3600
    
    # Exit signals
    exit_signal = None
    exit_urgency = 0
    ez = pos.get('exit_z_target', 0.5)
    # v5.0: Adaptive stop â€” at least 2.0 Z-units beyond entry, minimum 4.0
    default_stop = max(abs(pos['entry_z']) + 2.0, 4.0)
    sz = pos.get('stop_z', default_stop)
    max_hours = pos.get('max_hold_hours', 72)
    pnl_stop = pos.get('pnl_stop_pct', -5.0)
    
    if pos['direction'] == 'LONG':
        if z_now >= -ez and z_now <= ez:
            # v16: Check PnL before declaring convergence (Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğµ #1)
            # v18: Also check GARCH Z â€” if GARCH still far, it's variance collapse
            garch_still_far = abs(z_garch) > 1.5
            if pnl_pct > -0.3 and not garch_still_far:
                exit_signal = 'âœ… MEAN REVERT â€” Ğ·Ğ°ĞºÑ€Ñ‹Ğ²Ğ°Ñ‚ÑŒ!'
                exit_urgency = 2
            elif garch_still_far:
                exit_signal = (f'âš ï¸ Ğ›ĞĞ–ĞĞĞ• Ğ¡Ğ¥ĞĞ–Ğ”Ğ•ĞĞ˜Ğ•: Z_stdâ†’0 Ğ½Ğ¾ Z_GARCH={z_garch:+.1f}. '
                               f'Ïƒ Ğ²Ñ‹Ñ€Ğ¾ÑĞ»Ğ° Ğ² {garch_vol_ratio:.1f}x. Ğ ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ğ° Ğ½ĞµÑ‚.')
                exit_urgency = 1
            else:
                exit_signal = (f'âš ï¸ Ğ›ĞĞ–ĞĞĞ• Ğ¡Ğ¥ĞĞ–Ğ”Ğ•ĞĞ˜Ğ•: Zâ†’0 Ğ½Ğ¾ P&L={pnl_pct:+.2f}%. '
                               f'Ïƒ ÑĞ¿Ñ€ĞµĞ´Ğ° Ğ²Ñ‹Ñ€Ğ¾ÑĞ»Ğ°. Ğ–Ğ´Ğ¸Ñ‚Ğµ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ğ° Ñ†ĞµĞ½.')
                exit_urgency = 1
        elif z_now > 1.0:
            exit_signal = 'âœ… OVERSHOOT â€” Ñ„Ğ¸ĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ±Ñ‹Ğ»ÑŒ!'
            exit_urgency = 2
        elif z_now < -sz:
            exit_signal = 'ğŸ›‘ STOP LOSS (Z) â€” ÑĞºÑÑ‚Ñ€ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ñ…Ğ¾Ğ´!'
            exit_urgency = 2
    else:
        if z_now <= ez and z_now >= -ez:
            garch_still_far = abs(z_garch) > 1.5
            if pnl_pct > -0.3 and not garch_still_far:
                exit_signal = 'âœ… MEAN REVERT â€” Ğ·Ğ°ĞºÑ€Ñ‹Ğ²Ğ°Ñ‚ÑŒ!'
                exit_urgency = 2
            elif garch_still_far:
                exit_signal = (f'âš ï¸ Ğ›ĞĞ–ĞĞĞ• Ğ¡Ğ¥ĞĞ–Ğ”Ğ•ĞĞ˜Ğ•: Z_stdâ†’0 Ğ½Ğ¾ Z_GARCH={z_garch:+.1f}. '
                               f'Ïƒ Ğ²Ñ‹Ñ€Ğ¾ÑĞ»Ğ° Ğ² {garch_vol_ratio:.1f}x. Ğ ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ğ° Ğ½ĞµÑ‚.')
                exit_urgency = 1
            else:
                exit_signal = (f'âš ï¸ Ğ›ĞĞ–ĞĞĞ• Ğ¡Ğ¥ĞĞ–Ğ”Ğ•ĞĞ˜Ğ•: Zâ†’0 Ğ½Ğ¾ P&L={pnl_pct:+.2f}%. '
                               f'Ïƒ ÑĞ¿Ñ€ĞµĞ´Ğ° Ğ²Ñ‹Ñ€Ğ¾ÑĞ»Ğ°. Ğ–Ğ´Ğ¸Ñ‚Ğµ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ğ° Ñ†ĞµĞ½.')
                exit_urgency = 1
        elif z_now < -1.0:
            exit_signal = 'âœ… OVERSHOOT â€” Ñ„Ğ¸ĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ±Ñ‹Ğ»ÑŒ!'
            exit_urgency = 2
        elif z_now > sz:
            exit_signal = 'ğŸ›‘ STOP LOSS (Z) â€” ÑĞºÑÑ‚Ñ€ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ñ…Ğ¾Ğ´!'
            exit_urgency = 2
    
    # P&L stop
    if pnl_pct <= pnl_stop and exit_urgency < 2:
        exit_signal = f'ğŸ›‘ STOP LOSS (P&L {pnl_pct:.1f}% < {pnl_stop:.0f}%) â€” Ğ²Ñ‹Ñ…Ğ¾Ğ´!'
        exit_urgency = 2
    
    # Time-based
    if hours_in > max_hours and exit_urgency < 2:
        if exit_signal is None:
            exit_signal = f'â° TIMEOUT ({hours_in:.0f}Ñ‡ > {max_hours:.0f}Ñ‡) â€” Ñ€Ğ°ÑÑĞ¼Ğ¾Ñ‚Ñ€Ğ¸Ñ‚Ğµ Ğ²Ñ‹Ñ…Ğ¾Ğ´'
            exit_urgency = 1
    elif hours_in > max_hours * 0.75 and exit_urgency == 0:
        exit_signal = f'âš ï¸ ĞŸĞ¾Ğ·Ğ¸Ñ†Ğ¸Ñ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ğ° {hours_in:.0f}Ñ‡ (Ğ»Ğ¸Ğ¼Ğ¸Ñ‚ {max_hours:.0f}Ñ‡)'
        exit_urgency = 1
    
    # v27: Quality warnings â€” thresholds from unified config
    quality_warnings = []
    _h_crit = CFG('monitor', 'hurst_critical', 0.50)
    _h_warn = CFG('monitor', 'hurst_warning', 0.48)
    _h_border = CFG('monitor', 'hurst_border', 0.45)
    _pv_warn = CFG('monitor', 'pvalue_warning', 0.10)
    _corr_warn = CFG('monitor', 'correlation_warning', 0.20)
    
    if hurst >= _h_crit:
        quality_warnings.append(
            f"ğŸš¨ Hurst(EMA)={hurst:.3f} â‰¥ {_h_crit} â€” Ğ½ĞµÑ‚ mean reversion!"
            + (f" (raw={hurst_raw:.3f}, Ïƒ={hurst_std:.3f})" if hurst_std > 0 else ""))
    elif hurst >= _h_warn:
        quality_warnings.append(f"âš ï¸ Hurst(EMA)={hurst:.3f} â‰¥ {_h_warn} â€” Ğ¾ÑĞ»Ğ°Ğ±ĞµĞ²Ğ°ĞµÑ‚")
    elif hurst >= _h_border:
        quality_warnings.append(f"ğŸ’¡ Hurst(EMA)={hurst:.3f} â€” Ğ¿Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ½Ğ¾Ğµ")
    if pvalue >= _pv_warn:
        quality_warnings.append(f"âš ï¸ P-value={pvalue:.3f} â€” ĞºĞ¾Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¾ÑĞ»Ğ°Ğ±Ğ»Ğ°!")
    if corr < _corr_warn:
        quality_warnings.append(f"âš ï¸ ĞšĞ¾Ñ€Ñ€ĞµĞ»ÑÑ†Ğ¸Ñ Ï={corr:.2f} < {_corr_warn} â€” Ñ…ĞµĞ´Ğ¶ Ğ½Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚!")
    
    # v18: Direction sanity check â€” warn if direction contradicts entry Z
    entry_z = pos.get('entry_z', 0)
    direction = pos.get('direction', '')
    if entry_z < -0.5 and direction == 'SHORT':
        quality_warnings.append(
            f"ğŸš¨ ĞĞĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ˜Ğ• Ğ˜ĞĞ’Ğ•Ğ Ğ¢Ğ˜Ğ ĞĞ’ĞĞĞ: Entry_Z={entry_z:+.2f} (Ğ¾Ñ‚Ñ€Ğ¸Ñ†Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹) "
            f"Ğ½Ğ¾ Dir=SHORT. Ğ”Ğ»Ñ Z<0 Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ LONG! ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ Ğ²Ğ²Ğ¾Ğ´.")
    elif entry_z > 0.5 and direction == 'LONG':
        quality_warnings.append(
            f"ğŸš¨ ĞĞĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ˜Ğ• Ğ˜ĞĞ’Ğ•Ğ Ğ¢Ğ˜Ğ ĞĞ’ĞĞĞ: Entry_Z={entry_z:+.2f} (Ğ¿Ğ¾Ğ»Ğ¾Ğ¶Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹) "
            f"Ğ½Ğ¾ Dir=LONG. Ğ”Ğ»Ñ Z>0 Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ SHORT! ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ Ğ²Ğ²Ğ¾Ğ´.")
    
    # Build base result dict
    base_result = {
        'z_now': z_now,
        'z_entry': pos['entry_z'],
        'pnl_pct': pnl_pct,
        'spread_direction': spread_direction,
        'z_towards_zero': z_towards_zero,
        'pnl_z_disagree': pnl_z_disagree,
        'pnl_z_warning': pnl_z_warning,
        'price1_now': p1[-1],
        'price2_now': p2[-1],
        'hr_now': hr_current,
        'hr_entry': pos['entry_hr'],
        'exit_signal': exit_signal,
        'exit_urgency': exit_urgency,
        'hours_in': hours_in,
        'spread': spread,
        'zscore_series': zs,
        'timestamps': ts,
        'hr_series': kf['hrs'],
        'halflife_hours': hl_hours,
        'z_window': zw,
        'hurst': hurst,
        'correlation': corr,
        'pvalue': pvalue,
        'quality_data': quality_data,
        'quality_warnings': quality_warnings,
        'z_garch': z_garch,
        'garch_vol_ratio': garch_vol_ratio,
        'garch_var_expanding': garch_var_expanding,
    }
    
    # v27: R6 Correlation Monitor â€” track quality degradation
    _pair_key = f"{pos['coin1']}/{pos['coin2']}"
    _qh_key = f"_quality_history_{pos['id']}"
    if _qh_key not in st.session_state:
        st.session_state[_qh_key] = []
    _qh = st.session_state[_qh_key]
    _qh.append({'ts': time.time(), 'corr': corr, 'hurst': hurst, 'pval': pvalue})
    if len(_qh) > 30:
        st.session_state[_qh_key] = _qh[-30:]
    
    # R6: Quality degradation alerts
    if len(_qh) >= 3:
        _recent_corr = [q['corr'] for q in _qh[-5:]]
        _recent_hurst = [q['hurst'] for q in _qh[-5:]]
        _corr_trend = _recent_corr[-1] - _recent_corr[0] if len(_recent_corr) > 1 else 0
        _hurst_trend = _recent_hurst[-1] - _recent_hurst[0] if len(_recent_hurst) > 1 else 0
        
        if _corr_trend < -0.1:
            quality_warnings.append(f"ğŸ“‰ R6: Ï Ğ¿Ğ°Ğ´Ğ°ĞµÑ‚ ({_recent_corr[0]:.2f}â†’{_recent_corr[-1]:.2f}). Ğ¥ĞµĞ´Ğ¶ Ğ´ĞµĞ³Ñ€Ğ°Ğ´Ğ¸Ñ€ÑƒĞµÑ‚!")
        if _hurst_trend > 0.05:
            quality_warnings.append(f"ğŸ“ˆ R6: Hurst Ñ€Ğ°ÑÑ‚Ñ‘Ñ‚ ({_recent_hurst[0]:.3f}â†’{_recent_hurst[-1]:.3f}). MR Ğ¾ÑĞ»Ğ°Ğ±ĞµĞ²Ğ°ĞµÑ‚!")
    
    base_result['quality_warnings'] = quality_warnings
    
    # v24: R5 Smart Exit Analysis (was dead code â€” FIXED in v27)
    base_result['smart_exit'] = None
    base_result['smart_signals'] = []
    base_result['smart_recommendation'] = ''
    base_result['smart_urgency'] = 0
    
    if _USE_MRA:
        try:
            smart_exit = smart_exit_analysis(
                z_entry=pos['entry_z'],
                z_now=z_now,
                z_history=zs[~np.isnan(zs)] if len(zs) > 0 else np.array([z_now]),
                pnl_pct=pnl_pct,
                hours_in=hours_in,
                halflife_hours=hl_hours,
                direction=pos['direction'],
                best_pnl=pos.get('best_pnl', max(pnl_pct, 0)),
            )
            base_result['smart_exit'] = smart_exit
            base_result['smart_signals'] = smart_exit.get('signals', [])
            base_result['smart_recommendation'] = smart_exit.get('recommendation', '')
            base_result['smart_urgency'] = smart_exit.get('urgency', 0)
            
            # Override exit_signal if smart exit has higher urgency
            if smart_exit.get('urgency', 0) > exit_urgency:
                base_result['exit_urgency'] = smart_exit['urgency']
                smart_msgs = [s['message'] for s in smart_exit.get('signals', [])]
                if smart_msgs:
                    base_result['exit_signal'] = ' | '.join(smart_msgs[:2])
        except Exception:
            pass
    
    return base_result


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STREAMLIT UI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

st.set_page_config(page_title="Position Monitor", page_icon="ğŸ“", layout="wide")

st.markdown("""
<style>
    .exit-signal { padding: 15px; border-radius: 10px; font-size: 1.2em; 
                   font-weight: bold; text-align: center; margin: 10px 0; }
    .signal-exit { background: #1b5e20; color: #a5d6a7; }
    .signal-stop { background: #b71c1c; color: #ef9a9a; }
</style>
""", unsafe_allow_html=True)

st.title("ğŸ“ Pairs Position Monitor")
st.caption("v19.0 | 24.02.2026 | Unified Config + Auto-refresh FIX + R8/R5 Smart Exit")

# Sidebar
with st.sidebar:
    st.header("âš™ï¸ ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸")
    exchange = st.selectbox("Ğ‘Ğ¸Ñ€Ğ¶Ğ°", ['okx', 'kucoin', 'bybit', 'binance'], index=0,
                           help="âš ï¸ Binance/Bybit Ğ·Ğ°Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹ Ğ½Ğ° Ğ¾Ğ±Ğ»Ğ°Ñ‡Ğ½Ñ‹Ñ… ÑĞµÑ€Ğ²ĞµÑ€Ğ°Ñ…. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ OKX/KuCoin.")
    auto_refresh = st.checkbox("ĞĞ²Ñ‚Ğ¾-Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ (2 Ğ¼Ğ¸Ğ½)", value=False)
    
    st.divider()
    st.header("â• ĞĞ¾Ğ²Ğ°Ñ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ")
    
    # v22: R3 â€” Auto-Import from Scanner
    import glob, json as _json
    pending_files = sorted(glob.glob("monitor_import/pending_*.json"))
    
    # v27: Cleanup â€” remove pending files if pair already open
    if pending_files:
        _open_pairs = set()
        for _op in load_positions():
            if _op.get('status') == 'OPEN':
                _open_pairs.add(f"{_op['coin1']}/{_op['coin2']}")
        
        _remaining = []
        for pf in pending_files:
            try:
                with open(pf, 'r') as f:
                    imp = _json.load(f)
                _pname = f"{imp['coin1']}/{imp['coin2']}"
                if _pname in _open_pairs:
                    import os; os.remove(pf)  # Already imported
                else:
                    _remaining.append(pf)
            except Exception:
                _remaining.append(pf)
        pending_files = _remaining
    
    if pending_files:
        st.markdown("#### ğŸ“¥ Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ¸Ğ· ÑĞºĞ°Ğ½ĞµÑ€Ğ°")
        for pf in pending_files:
            try:
                with open(pf, 'r') as f:
                    imp = _json.load(f)
                pair_name = f"{imp['coin1']}/{imp['coin2']}"
                st.info(
                    f"ğŸ“¤ **{pair_name}** {imp['direction']} | "
                    f"Z={imp['entry_z']:.2f} HR={imp['entry_hr']:.4f} "
                    f"| {imp.get('notes', '')}"
                )
                if st.button(f"âœ… Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ {pair_name}", key=f"imp_{pair_name}"):
                    with st.spinner(f"Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°Ñ Ñ†ĞµĞ½Ñ‹ {pair_name}..."):
                        p1 = imp.get('entry_price1', 0)
                        p2 = imp.get('entry_price2', 0)
                        if p1 == 0 or p2 == 0:
                            p1 = get_current_price(exchange, imp['coin1']) or 0
                            p2 = get_current_price(exchange, imp['coin2']) or 0
                        if p1 > 0 and p2 > 0:
                            pos = add_position(
                                imp['coin1'], imp['coin2'], imp['direction'],
                                imp['entry_z'], imp['entry_hr'],
                                p1, p2, imp.get('timeframe', '4h'),
                                imp.get('notes', ''))
                            st.success(f"âœ… #{pos['id']} {pair_name} Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ°!")
                            import os; os.remove(pf)
                            st.rerun()
                        else:
                            st.error("ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ñ†ĞµĞ½Ñ‹")
            except Exception as ex:
                st.warning(f"âš ï¸ {pf}: {ex}")
        st.divider()
    
    # Upload JSON manually
    uploaded_json = st.file_uploader("ğŸ“¤ Ğ˜Ğ»Ğ¸ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸ JSON Ğ¸Ğ· ÑĞºĞ°Ğ½ĞµÑ€Ğ°", type=['json'], key='json_import')
    if uploaded_json:
        try:
            imp = _json.load(uploaded_json)
            pair_name = f"{imp['coin1']}/{imp['coin2']}"
            st.info(f"ğŸ“¤ **{pair_name}** {imp['direction']} Z={imp['entry_z']:.2f} HR={imp['entry_hr']:.4f}")
            if st.button(f"âœ… Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ {pair_name}", key="imp_upload"):
                with st.spinner("Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°Ñ Ñ†ĞµĞ½Ñ‹..."):
                    p1 = imp.get('entry_price1', 0) or get_current_price(exchange, imp['coin1']) or 0
                    p2 = imp.get('entry_price2', 0) or get_current_price(exchange, imp['coin2']) or 0
                    if p1 > 0 and p2 > 0:
                        pos = add_position(imp['coin1'], imp['coin2'], imp['direction'],
                                         imp['entry_z'], imp['entry_hr'], p1, p2,
                                         imp.get('timeframe', '4h'), imp.get('notes', ''))
                        st.success(f"âœ… #{pos['id']} Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ°!")
                        st.rerun()
        except Exception as ex:
            st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° JSON: {ex}")
    
    st.divider()
    
    with st.form("add_position"):
        col1, col2 = st.columns(2)
        with col1:
            new_c1 = st.text_input("Coin 1", "ETH").upper().strip()
        with col2:
            new_c2 = st.text_input("Coin 2", "STETH").upper().strip()
        
        new_dir = st.selectbox("ĞĞ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ", ["LONG", "SHORT"])
        new_tf = st.selectbox("Ğ¢Ğ°Ğ¹Ğ¼Ñ„Ñ€ĞµĞ¹Ğ¼", ['1h', '4h', '1d'], index=1)
        
        col3, col4 = st.columns(2)
        with col3:
            new_z = st.number_input("Entry Z", value=2.0, step=0.1)
        with col4:
            new_hr = st.number_input("Hedge Ratio", value=1.0, step=0.01, format="%.4f")
        
        col5, col6 = st.columns(2)
        with col5:
            new_p1 = st.number_input("Ğ¦ĞµĞ½Ğ° Coin1", value=0.0, step=0.01, format="%.4f")
        with col6:
            new_p2 = st.number_input("Ğ¦ĞµĞ½Ğ° Coin2", value=0.0, step=0.01, format="%.4f")
        
        new_notes = st.text_input("Ğ—Ğ°Ğ¼ĞµÑ‚ĞºĞ¸", "")
        
        # v2.0: Risk management
        st.markdown("**âš ï¸ Ğ Ğ¸ÑĞº-Ğ¼ĞµĞ½ĞµĞ´Ğ¶Ğ¼ĞµĞ½Ñ‚**")
        col_r1, col_r2 = st.columns(2)
        with col_r1:
            new_max_hours = st.number_input("Max Ñ‡Ğ°ÑĞ¾Ğ² Ğ² Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸", value=72, step=12)
        with col_r2:
            new_pnl_stop = st.number_input("P&L Stop (%)", value=-5.0, step=0.5)
        
        # ĞĞ²Ñ‚Ğ¾Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ñ†ĞµĞ½
        fetch_prices_btn = st.form_submit_button("ğŸ“¥ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ñ†ĞµĞ½Ñ‹ + Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ")
    
    if fetch_prices_btn and new_c1 and new_c2:
        if new_p1 == 0 or new_p2 == 0:
            with st.spinner("Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°Ñ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğµ Ñ†ĞµĞ½Ñ‹..."):
                p1_live = get_current_price(exchange, new_c1)
                p2_live = get_current_price(exchange, new_c2)
                if p1_live and p2_live:
                    new_p1 = p1_live
                    new_p2 = p2_live
                    st.info(f"ğŸ’° {new_c1}: ${p1_live:.4f} | {new_c2}: ${p2_live:.4f}")
                else:
                    st.error("ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ñ†ĞµĞ½Ñ‹")
        
        if new_p1 > 0 and new_p2 > 0:
            # v22: HR sanity check â€” warn if HR doesn't match price ratio
            expected_hr_approx = new_p1 / new_p2 if new_p2 > 0 else 0
            if new_hr > 0 and expected_hr_approx > 0:
                ratio = new_hr / expected_hr_approx if expected_hr_approx > 0 else 999
                if ratio > 10 or ratio < 0.1:
                    st.warning(
                        f"âš ï¸ **HR Ğ¿Ğ¾Ğ´Ğ¾Ğ·Ñ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹!** HR={new_hr:.4f}, "
                        f"P1/P2={expected_hr_approx:.4f} (Ğ¾Ñ‚Ğ½Ğ¾ÑˆĞµĞ½Ğ¸Ğµ {ratio:.1f}x). "
                        f"ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ HR. Ğ’Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¾Ğ¿ĞµÑ‡Ğ°Ñ‚ĞºĞ°.")
            
            pos = add_position(new_c1, new_c2, new_dir, new_z, new_hr,
                             new_p1, new_p2, new_tf, new_notes,
                             max_hold_hours=new_max_hours,
                             pnl_stop_pct=new_pnl_stop)
            st.success(f"âœ… ĞŸĞ¾Ğ·Ğ¸Ñ†Ğ¸Ñ #{pos['id']} Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ°: {new_dir} {new_c1}/{new_c2}")
            st.rerun()

# â•â•â•â•â•â•â• MAIN AREA â•â•â•â•â•â•â•
positions = load_positions()
open_positions = [p for p in positions if p['status'] == 'OPEN']
closed_positions = [p for p in positions if p['status'] == 'CLOSED']

# Tabs
tab1, tab2, tab3, tab4 = st.tabs([f"ğŸ“ ĞÑ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ğµ ({len(open_positions)})", 
                       f"ğŸ“‹ Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ ({len(closed_positions)})",
                       f"ğŸ“Š ĞŸĞ¾Ñ€Ñ‚Ñ„ĞµĞ»ÑŒ",
                       f"ğŸ“ˆ Performance (R8)"])

with tab1:
    if not open_positions:
        st.info("ğŸ“­ ĞĞµÑ‚ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ñ… Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¹. Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒÑ‚Ğµ Ñ‡ĞµÑ€ĞµĞ· Ğ±Ğ¾ĞºĞ¾Ğ²ÑƒÑ Ğ¿Ğ°Ğ½ĞµĞ»ÑŒ.")
    else:
        # Dashboard metrics
        total_pnl = 0
        
        for pos in open_positions:
            with st.container():
                st.markdown("---")
                
                # Header
                dir_emoji = 'ğŸŸ¢' if pos['direction'] == 'LONG' else 'ğŸ”´'
                pair_name = f"{pos['coin1']}/{pos['coin2']}"
                
                # Monitor
                with st.spinner(f"ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑÑ {pair_name}..."):
                    mon = monitor_position(pos, exchange)
                
                if mon is None:
                    st.error(f"âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ {pair_name}")
                    continue
                
                total_pnl += mon['pnl_pct']
                
                # v24: Track best P&L for trailing stop
                current_best = pos.get('best_pnl', 0)
                if mon['pnl_pct'] > current_best:
                    pos['best_pnl'] = mon['pnl_pct']
                    # Save updated best_pnl
                    try:
                        all_pos = load_positions()
                        for p in all_pos:
                            if p['id'] == pos['id']:
                                p['best_pnl'] = mon['pnl_pct']
                        save_positions(all_pos)
                    except Exception:
                        pass
                
                # Exit signal banner
                if mon['exit_signal']:
                    if 'STOP' in mon['exit_signal'] or 'Ğ¡Ğ ĞĞ§Ğ' in str(mon['exit_signal']):
                        st.error(mon['exit_signal'])
                    elif 'MEAN REVERT' in mon['exit_signal'] or 'OVERSHOOT' in mon['exit_signal']:
                        st.success(mon['exit_signal'])
                    else:
                        st.warning(mon['exit_signal'])
                
                # v24: R5 Smart Exit Signals panel
                smart_sigs = mon.get('smart_signals', [])
                smart_rec = mon.get('smart_recommendation', '')
                if smart_sigs:
                    with st.expander(f"ğŸ§  Smart Exit: {smart_rec} ({len(smart_sigs)} ÑĞ¸Ğ³Ğ½Ğ°Ğ»{'Ğ¾Ğ²' if len(smart_sigs) > 1 else ''})", expanded=mon.get('smart_urgency', 0) >= 2):
                        for sig in smart_sigs:
                            sig_type = sig.get('type', '')
                            sig_urg = sig.get('urgency', 0)
                            if sig_urg >= 3:
                                st.error(sig['message'])
                            elif sig_urg >= 2:
                                st.warning(sig['message'])
                            else:
                                st.info(sig['message'])
                
                # Header row
                dir_emoji_c1 = 'ğŸŸ¢ LONG' if pos['direction'] == 'LONG' else 'ğŸ”´ SHORT'
                dir_emoji_c2 = 'ğŸ”´ SHORT' if pos['direction'] == 'LONG' else 'ğŸŸ¢ LONG'
                st.subheader(f"{dir_emoji} {pos['direction']} | {pair_name} | #{pos['id']}")
                st.caption(f"{pos['coin1']}: {dir_emoji_c1} | {pos['coin2']}: {dir_emoji_c2}")
                
                # v4.0: P&L / Z disagreement warning
                if mon.get('pnl_z_disagree'):
                    st.warning(mon['pnl_z_warning'])
                
                # KPI row
                c1, c2, c3, c4, c5, c6 = st.columns(6)
                
                # v23: Fix color display â€” Streamlit colors delta green=up, red=down
                # v24: P&L with CORRECT coloring
                # Streamlit st.metric: numeric delta â†’ green if positive, red if negative
                # String delta "loss" was showing as green text â€” WRONG!
                # Fix: pass NUMERIC delta so Streamlit applies correct color
                pnl_val = mon['pnl_pct']
                pnl_emoji = "ğŸŸ¢" if pnl_val > 0.01 else "ğŸ”´" if pnl_val < -0.01 else "âšª"
                c1.metric(
                    f"P&L {pnl_emoji}", 
                    f"{pnl_val:+.2f}%", 
                    delta=f"{pnl_val:+.2f}%",  # String starting with - â†’ red, + â†’ green
                    delta_color="normal"  # positive=green, negative=red
                )
                
                # v22: Directional Z explanation
                z_dir_ok = mon.get('z_towards_zero', False)
                z_crossed_zero = (pos['direction'] == 'LONG' and mon['z_now'] > 0 and pos['entry_z'] < 0) or \
                                 (pos['direction'] == 'SHORT' and mon['z_now'] < 0 and pos['entry_z'] > 0)
                if z_crossed_zero:
                    z_delta_text = f"âœ… OVERSHOOT (Ğ²Ñ…Ğ¾Ğ´: {mon['z_entry']:+.2f})"
                elif z_dir_ok:
                    z_delta_text = f"âœ… â†’ 0 (Ğ²Ñ…Ğ¾Ğ´: {mon['z_entry']:+.2f})"
                else:
                    z_delta_text = f"âŒ â† Ğ¾Ñ‚ 0 (Ğ²Ñ…Ğ¾Ğ´: {mon['z_entry']:+.2f})"
                c2.metric("Z ÑĞµĞ¹Ñ‡Ğ°Ñ", f"{mon['z_now']:+.2f}",
                         delta=z_delta_text)
                c3.metric("HR", f"{mon['hr_now']:.4f}",
                         delta=f"Ğ²Ñ…Ğ¾Ğ´: {mon['hr_entry']:.4f}")
                
                # v23: Price display with directional coloring
                # Coin1: LONG=want price UP, SHORT=want price DOWN
                p1_now = mon['price1_now']
                p1_entry = pos['entry_price1']
                p1_change = (p1_now - p1_entry) / p1_entry * 100 if p1_entry > 0 else 0
                # For LONG coin1: price up = good (green), For SHORT coin1: price down = good
                p1_good = (pos['direction'] == 'LONG' and p1_change >= 0) or \
                          (pos['direction'] == 'SHORT' and p1_change <= 0)
                c4.metric(
                    f"{pos['coin1']} {'ğŸŸ¢' if pos['direction']=='LONG' else 'ğŸ”´'}", 
                    f"${p1_now:.4f}",
                    delta=f"{p1_change:+.2f}% (Ğ²Ñ…Ğ¾Ğ´: ${p1_entry:.4f})",
                    delta_color="normal" if p1_good else "inverse")
                
                # Coin2: opposite direction to coin1
                p2_now = mon['price2_now']
                p2_entry = pos['entry_price2']
                p2_change = (p2_now - p2_entry) / p2_entry * 100 if p2_entry > 0 else 0
                # For LONG: coin2 is SHORT (want price down), For SHORT: coin2 is LONG (want price up)
                p2_good = (pos['direction'] == 'LONG' and p2_change <= 0) or \
                          (pos['direction'] == 'SHORT' and p2_change >= 0)
                c5.metric(
                    f"{pos['coin2']} {'ğŸ”´' if pos['direction']=='LONG' else 'ğŸŸ¢'}", 
                    f"${p2_now:.4f}",
                    delta=f"{p2_change:+.2f}% (Ğ²Ñ…Ğ¾Ğ´: ${p2_entry:.4f})",
                    delta_color="normal" if p2_good else "inverse")
                
                c6.metric("Ğ’ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸", f"{mon['hours_in']:.0f}Ñ‡",
                         delta=f"HL: {mon['halflife_hours']:.0f}Ñ‡")
                
                # v3.0: Quality metrics row
                q1, q2, q3, q4 = st.columns(4)
                q1.metric("Hurst", f"{mon.get('hurst', 0.5):.3f}",
                         delta="ğŸŸ¢ MR" if mon.get('hurst', 0.5) < 0.45 else "ğŸ”´ No MR")
                q2.metric("P-value", f"{mon.get('pvalue', 1.0):.4f}",
                         delta="âœ… Coint" if mon.get('pvalue', 1.0) < 0.05 else "âš ï¸ Weak")
                q3.metric("ĞšĞ¾Ñ€Ñ€ĞµĞ»ÑÑ†Ğ¸Ñ Ï", f"{mon.get('correlation', 0):.3f}",
                         delta="ğŸŸ¢" if mon.get('correlation', 0) >= 0.5 else "âš ï¸")
                q4.metric("Z-window", f"{mon.get('z_window', 30)} Ğ±Ğ°Ñ€Ğ¾Ğ²")
                
                # v18: GARCH Z row
                if mon.get('z_garch') is not None:
                    gq1, gq2, gq3, gq4 = st.columns(4)
                    gq1.metric("Z GARCH", f"{mon.get('z_garch', 0):+.2f}",
                               f"vs std={mon.get('z_now',0):+.2f}")
                    vr = mon.get('garch_vol_ratio', 1.0)
                    gq2.metric("Ïƒ ratio", f"{vr:.2f}x",
                               "ğŸ”´ Ñ€Ğ°ÑÑ‚Ñ‘Ñ‚" if mon.get('garch_var_expanding') else "âœ… ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ°")
                    gq3.metric("HL Ñ‡Ğ°ÑĞ¾Ğ²", f"{mon.get('halflife_hours', 0):.1f}")
                    gq4.metric("Z-window", f"{mon.get('z_window', 30)} Ğ±Ğ°Ñ€")
                
                # v20: Dynamic HR Drift Monitoring (P4 Roadmap)
                hr_entry = pos.get('entry_hr', 0)
                hr_now = mon.get('hr_now', hr_entry)
                if hr_entry > 0 and hr_now > 0:
                    hr_drift_pct = abs(hr_now - hr_entry) / hr_entry * 100
                    
                    if hr_drift_pct > 5:  # Only show if drift is significant
                        st.markdown("#### ğŸ“ HR Drift Monitor")
                        hd1, hd2, hd3 = st.columns(3)
                        with hd1:
                            dr_emoji = 'âœ…' if hr_drift_pct < 10 else 'ğŸŸ¡' if hr_drift_pct < 20 else 'ğŸ”´'
                            st.metric("HR Ğ´Ñ€ĞµĞ¹Ñ„", f"{dr_emoji} {hr_drift_pct:.1f}%",
                                     f"Entry: {hr_entry:.4f} â†’ Now: {hr_now:.4f}")
                        with hd2:
                            # Calculate impact: how much spread changed due to HR drift alone
                            p2_now = mon.get('price2_now', pos.get('entry_price2', 1))
                            hr_impact = abs(hr_now - hr_entry) * p2_now
                            st.metric("Ğ’Ğ»Ğ¸ÑĞ½Ğ¸Ğµ Ğ½Ğ° ÑĞ¿Ñ€ĞµĞ´", f"{hr_impact:.4f}",
                                     "USD ÑĞ´Ğ²Ğ¸Ğ³ Ğ¾Ñ‚ Ğ´Ñ€ĞµĞ¹Ñ„Ğ° HR")
                        with hd3:
                            # Rebalance suggestion
                            if hr_drift_pct > 15:
                                st.metric("Ğ ĞµĞ±Ğ°Ğ»Ğ°Ğ½Ñ", "ğŸ”´ ĞĞ£Ğ–Ğ•Ğ",
                                         f"HR Ğ¸Ğ·Ğ¼ĞµĞ½Ğ¸Ğ»ÑÑ Ğ½Ğ° {hr_drift_pct:.0f}%")
                            elif hr_drift_pct > 10:
                                st.metric("Ğ ĞµĞ±Ğ°Ğ»Ğ°Ğ½Ñ", "ğŸŸ¡ Ğ Ğ°ÑÑĞ¼Ğ¾Ñ‚Ñ€Ğ¸Ñ‚Ğµ",
                                         f"HR Ğ´Ñ€ĞµĞ¹Ñ„ÑƒĞµÑ‚")
                            else:
                                st.metric("Ğ ĞµĞ±Ğ°Ğ»Ğ°Ğ½Ñ", "âœ… ĞĞµ Ğ½ÑƒĞ¶ĞµĞ½", "Ğ”Ñ€ĞµĞ¹Ñ„ Ğ² Ğ½Ğ¾Ñ€Ğ¼Ğµ")
                        
                        if hr_drift_pct > 100:
                            st.error(
                                f"ğŸš¨ **ĞĞ¨Ğ˜Ğ‘ĞšĞ Ğ’Ğ’ĞĞ”Ğ HR?** Ğ”Ñ€ĞµĞ¹Ñ„ {hr_drift_pct:.0f}% â€” "
                                f"Entry={hr_entry:.4f}, Now={hr_now:.4f}. "
                                f"Ğ’ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ HR Ğ±Ñ‹Ğ» Ğ²Ğ²ĞµĞ´Ñ‘Ğ½ Ğ½ĞµĞ²ĞµÑ€Ğ½Ğ¾ Ğ¿Ñ€Ğ¸ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ğ¸Ğ¸ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸. "
                                f"**ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ Ğ¸ Ğ¿ĞµÑ€ĞµÑĞ¾Ğ·Ğ´Ğ°Ğ¹Ñ‚Ğµ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ Ñ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¼ HR!**")
                        elif hr_drift_pct > 20:
                            st.error(
                                f"ğŸš¨ **HR Ğ”Ğ Ğ•Ğ™Ğ¤ ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ™: {hr_drift_pct:.1f}%**. "
                                f"Entry HR={hr_entry:.4f}, Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğ¹={hr_now:.4f}. "
                                f"ĞšĞ¾Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¼Ğ¾Ğ³Ğ»Ğ° Ñ€Ğ°Ğ·Ñ€ÑƒÑˆĞ¸Ñ‚ÑŒÑÑ. Ğ Ğ°ÑÑĞ¼Ğ¾Ñ‚Ñ€Ğ¸Ñ‚Ğµ Ğ·Ğ°ĞºÑ€Ñ‹Ñ‚Ğ¸Ğµ.")
                        elif hr_drift_pct > 15:
                            st.warning(
                                f"âš ï¸ **HR Ğ´Ñ€ĞµĞ¹Ñ„ {hr_drift_pct:.1f}%**: Entry={hr_entry:.4f}, "
                                f"Now={hr_now:.4f}. Ğ ĞµĞ±Ğ°Ğ»Ğ°Ğ½ÑĞ¸Ñ€ÑƒĞ¹Ñ‚Ğµ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ Ğ¸Ğ»Ğ¸ Ğ·Ğ°ĞºÑ€Ğ¾Ğ¹Ñ‚Ğµ.")
                
                # v3.0: Quality warnings
                for qw in mon.get('quality_warnings', []):
                    st.warning(qw)
                
                # v3.0: Entry readiness assessment
                qd = mon.get('quality_data', {})
                if qd:
                    ea = assess_entry_readiness(qd)
                    with st.expander("ğŸ“‹ ĞšÑ€Ğ¸Ñ‚ĞµÑ€Ğ¸Ğ¸ Ğ²Ñ…Ğ¾Ğ´Ğ° (ĞºĞ°Ğº Ğ² ÑĞºĞ°Ğ½ĞµÑ€Ğµ)", expanded=False):
                        ec1, ec2 = st.columns(2)
                        with ec1:
                            st.markdown("**ğŸŸ¢ ĞĞ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ:**")
                            for name, met, val in ea['mandatory']:
                                st.markdown(f"  {'âœ…' if met else 'âŒ'} **{name}** â†’ `{val}`")
                        with ec2:
                            st.markdown("**ğŸ”µ Ğ–ĞµĞ»Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ:**")
                            for name, met, val in ea['optional']:
                                st.markdown(f"  {'âœ…' if met else 'â¬œ'} {name} â†’ `{val}`")
                
                # Chart
                with st.expander("ğŸ“ˆ Ğ“Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸", expanded=False):
                    fig = make_subplots(rows=2, cols=1, shared_xaxes=True,
                                       vertical_spacing=0.08,
                                       subplot_titles=['Z-Score', 'Ğ¡Ğ¿Ñ€ĞµĞ´'],
                                       row_heights=[0.6, 0.4])
                    
                    ts = mon['timestamps']
                    
                    # Z-score
                    fig.add_trace(go.Scatter(
                        x=ts, y=mon['zscore_series'],
                        name='Z-Score', line=dict(color='#4fc3f7', width=2)
                    ), row=1, col=1)
                    
                    fig.add_hline(y=0, line_dash='dash', line_color='gray', 
                                 opacity=0.5, row=1, col=1)
                    fig.add_hline(y=pos.get('exit_z_target', 0.5), 
                                 line_dash='dot', line_color='#4caf50',
                                 opacity=0.5, row=1, col=1)
                    fig.add_hline(y=-pos.get('exit_z_target', 0.5), 
                                 line_dash='dot', line_color='#4caf50',
                                 opacity=0.5, row=1, col=1)
                    
                    # Entry Z marker
                    entry_dt = datetime.fromisoformat(pos['entry_time'])
                    fig.add_trace(go.Scatter(
                        x=[entry_dt], y=[pos['entry_z']],
                        mode='markers', marker=dict(size=14, color='yellow',
                                                     symbol='star'),
                        name='Entry', showlegend=True
                    ), row=1, col=1)
                    
                    # Spread
                    fig.add_trace(go.Scatter(
                        x=ts, y=mon['spread'],
                        name='Spread', line=dict(color='#ffa726', width=1.5)
                    ), row=2, col=1)
                    
                    fig.update_layout(height=400, template='plotly_dark',
                                     showlegend=False,
                                     margin=dict(l=50, r=30, t=30, b=30))
                    st.plotly_chart(fig, use_container_width=True)
                
                # Close button
                col_close1, col_close2, col_close3 = st.columns([2, 2, 1])
                with col_close3:
                    if st.button(f"âŒ Ğ—Ğ°ĞºÑ€Ñ‹Ñ‚ÑŒ #{pos['id']}", key=f"close_{pos['id']}"):
                        close_position(
                            pos['id'], 
                            mon['price1_now'], mon['price2_now'],
                            mon['z_now'], 'MANUAL'
                        )
                        st.success(f"ĞŸĞ¾Ğ·Ğ¸Ñ†Ğ¸Ñ #{pos['id']} Ğ·Ğ°ĞºÑ€Ñ‹Ñ‚Ğ° | P&L: {mon['pnl_pct']:+.2f}%")
                        st.rerun()
        
        # Total P&L
        st.markdown("---")
        st.metric("ğŸ“Š Ğ¡ÑƒĞ¼Ğ¼Ğ°Ñ€Ğ½Ñ‹Ğ¹ P&L (Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ğµ)", f"{total_pnl:+.2f}%")
        
        # v5.2: FULL open positions CSV with live monitoring data
        open_rows = []
        for pos in open_positions:
            row = {
                '#': pos['id'],
                'ĞŸĞ°Ñ€Ğ°': f"{pos['coin1']}/{pos['coin2']}",
                'Dir': pos['direction'],
                'TF': pos['timeframe'],
                'Entry_Z': pos['entry_z'],
                'Entry_HR': pos.get('entry_hr', 0),
                'Stop_Z': pos.get('stop_z', 4.0),
                'Entry_Time': pos['entry_time'][:16],
                'Entry_Price1': pos.get('entry_price1', 0),
                'Entry_Price2': pos.get('entry_price2', 0),
            }
            # Add live data if available
            try:
                mon = monitor_position(pos, exchange)
                if mon:
                    row.update({
                        'Current_Z': round(mon['z_now'], 4),
                        'Current_HR': round(mon['hr_now'], 4),
                        'P&L_%': round(mon['pnl_pct'], 4),
                        'Hours_In': round(mon['hours_in'], 1),
                        'HL_hours': round(mon['halflife_hours'], 1),
                        'Price1_Now': round(mon['price1_now'], 6),
                        'Price2_Now': round(mon['price2_now'], 6),
                        'Hurst': round(mon.get('hurst', 0.5), 4),
                        'Correlation': round(mon.get('correlation', 0), 4),
                        'P-value': round(mon.get('pvalue', 1.0), 6),
                        'Z_Window': mon.get('z_window', 30),
                        'Exit_Signal': mon.get('exit_signal', ''),
                        'Exit_Urgency': mon.get('exit_urgency', ''),
                        'Z_Toward_Zero': mon.get('z_towards_zero', False),
                        'PnL_Z_Disagree': mon.get('pnl_z_disagree', False),
                        'Quality_Warnings': '; '.join(mon.get('quality_warnings', [])),
                    })
            except Exception:
                pass
            open_rows.append(row)
        
        if open_rows:
            csv_open = pd.DataFrame(open_rows).to_csv(index=False)
            st.download_button("ğŸ“¥ Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ğµ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ (CSV)", csv_open,
                f"positions_open_{now_msk().strftime('%Y%m%d_%H%M')}.csv", "text/csv",
                key="open_pos_csv")
            
            # v20.1: Auto-save positions to disk every 10 minutes
            try:
                import os
                os.makedirs("position_exports", exist_ok=True)
                last_auto_save = st.session_state.get('_last_pos_save', 0)
                now_ts = time.time()
                if now_ts - last_auto_save > 600:  # 10 minutes
                    save_path = f"position_exports/positions_open_{now_msk().strftime('%Y%m%d_%H%M')}.csv"
                    pd.DataFrame(open_rows).to_csv(save_path, index=False)
                    st.session_state['_last_pos_save'] = now_ts
                    st.toast(f"ğŸ’¾ ĞŸĞ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹: {save_path}")
            except Exception:
                pass

with tab2:
    if not closed_positions:
        st.info("ğŸ“­ ĞĞµÑ‚ Ğ·Ğ°ĞºÑ€Ñ‹Ñ‚Ñ‹Ñ… Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¹")
    else:
        # Summary
        pnls = [p.get('pnl_pct', 0) for p in closed_positions]
        wins = [p for p in pnls if p > 0]
        
        sc1, sc2, sc3, sc4 = st.columns(4)
        sc1.metric("Ğ¡Ğ´ĞµĞ»Ğ¾Ğº", len(closed_positions))
        sc2.metric("Win Rate", f"{len(wins)/len(closed_positions)*100:.0f}%" if closed_positions else "0%")
        sc3.metric("Total P&L", f"{sum(pnls):+.2f}%")
        sc4.metric("Avg P&L", f"{np.mean(pnls):+.2f}%" if pnls else "0%")
        
        # Table
        rows = []
        for p in reversed(closed_positions):
            rows.append({
                '#': p['id'],
                'ĞŸĞ°Ñ€Ğ°': f"{p['coin1']}/{p['coin2']}",
                'Dir': p['direction'],
                'TF': p['timeframe'],
                'Entry Z': f"{p['entry_z']:+.2f}",
                'Exit Z': f"{p.get('exit_z', 0):+.2f}",
                'P&L %': f"{p.get('pnl_pct', 0):+.2f}",
                'ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ°': p.get('exit_reason', ''),
                'Ğ’Ñ…Ğ¾Ğ´': p['entry_time'][:16],
                'Ğ’Ñ‹Ñ…Ğ¾Ğ´': p.get('exit_time', '')[:16] if p.get('exit_time') else '',
            })
        st.dataframe(pd.DataFrame(rows), use_container_width=True, hide_index=True)
        
        # v5.1: CSV export with date in filename
        csv_history = pd.DataFrame(rows).to_csv(index=False)
        # Date range from trades
        dates = [p.get('exit_time', '')[:10] for p in closed_positions if p.get('exit_time')]
        date_suffix = dates[-1] if dates else now_msk().strftime('%Y-%m-%d')
        st.download_button("ğŸ“¥ Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ ÑĞ´ĞµĞ»Ğ¾Ğº (CSV)", csv_history,
                          f"trades_history_{date_suffix}_{now_msk().strftime('%H%M')}.csv", "text/csv")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TAB 3: PORTFOLIO RISK MANAGER (v19.0)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with tab3:
    if not open_positions:
        st.info("ğŸ“­ ĞĞµÑ‚ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ñ… Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ¿Ğ¾Ñ€Ñ‚Ñ„ĞµĞ»Ñ.")
    else:
        st.markdown("### ğŸ“Š Portfolio Risk Manager v2.0")
        
        # === 1. Collect all monitoring data upfront ===
        mon_cache = {}
        for pos in open_positions:
            pair = f"{pos['coin1']}/{pos['coin2']}"
            try:
                mon = monitor_position(pos, exchange)
                if mon:
                    mon_cache[pos['id']] = mon
            except Exception:
                pass
        
        # === 2. Portfolio summary metrics ===
        total_pnl_port = sum(m['pnl_pct'] for m in mon_cache.values())
        n_pos = len(open_positions)
        n_profit = sum(1 for m in mon_cache.values() if m['pnl_pct'] > 0)
        n_loss = sum(1 for m in mon_cache.values() if m['pnl_pct'] < 0)
        
        pc1, pc2, pc3, pc4 = st.columns(4)
        pc1.metric("ĞŸĞ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¹", n_pos)
        pc2.metric("Ğ¡Ğ¾Ğ²Ğ¾ĞºÑƒĞ¿Ğ½Ñ‹Ğ¹ P&L", f"{total_pnl_port:+.3f}%")
        pc3.metric("ĞŸÑ€Ğ¸Ğ±Ñ‹Ğ»ÑŒĞ½Ñ‹Ñ…", f"{n_profit}/{n_pos}",
                  f"{n_profit/n_pos*100:.0f}%" if n_pos > 0 else "â€”")
        avg_hours = sum(pos.get('hours_in', 0) for pos in open_positions) / n_pos if n_pos > 0 else 0
        pc4.metric("Ğ¡Ñ€. Ğ²Ñ€ĞµĞ¼Ñ Ğ² Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸", f"{avg_hours:.1f}Ñ‡")
        
        # === 3. Coin exposure map ===
        st.markdown("#### ğŸª™ Ğ­ĞºÑĞ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ Ğ¿Ğ¾ Ğ¼Ğ¾Ğ½ĞµÑ‚Ğ°Ğ¼")
        coin_exposure = {}
        for pos in open_positions:
            c1, c2 = pos['coin1'], pos['coin2']
            d = pos['direction']
            for coin, coin_dir in [(c1, d), (c2, 'SHORT' if d == 'LONG' else 'LONG')]:
                if coin not in coin_exposure:
                    coin_exposure[coin] = {'long': 0, 'short': 0, 'pairs': [], 'pnl': 0.0}
                if coin_dir == 'LONG':
                    coin_exposure[coin]['long'] += 1
                else:
                    coin_exposure[coin]['short'] += 1
                coin_exposure[coin]['pairs'].append(f"{c1}/{c2}")
                mon = mon_cache.get(pos['id'])
                if mon:
                    coin_exposure[coin]['pnl'] += mon['pnl_pct'] / 2  # Split P&L between legs
        
        for coin, data in coin_exposure.items():
            data['net'] = data['long'] - data['short']
            data['total'] = data['long'] + data['short']
        
        sorted_coins = sorted(coin_exposure.items(), key=lambda x: x[1]['total'], reverse=True)
        
        # Concentration metric
        max_coin = sorted_coins[0] if sorted_coins else ('â€”', {'total': 0})
        max_exposure_pct = max_coin[1]['total'] / (n_pos * 2) * 100 if n_pos > 0 else 0
        
        # Exposure table
        coin_rows = []
        for coin, data in sorted_coins:
            conflict = 'ğŸš¨ ĞšĞĞĞ¤Ğ›Ğ˜ĞšĞ¢' if data['long'] > 0 and data['short'] > 0 else ''
            pct_of_port = data['total'] / (n_pos * 2) * 100 if n_pos > 0 else 0
            bar = 'â–ˆ' * int(pct_of_port / 5) + 'â–‘' * (20 - int(pct_of_port / 5))
            coin_rows.append({
                'ĞœĞ¾Ğ½ĞµÑ‚Ğ°': coin,
                'LONG': data['long'],
                'SHORT': data['short'],
                'Ğ’ÑĞµĞ³Ğ¾': data['total'],
                'Net': f"+{data['net']}" if data['net'] > 0 else str(data['net']),
                '% Ğ¿Ğ¾Ñ€Ñ‚.': f"{pct_of_port:.0f}%",
                'P&L': f"{data['pnl']:+.3f}%",
                'ĞšĞ¾Ğ½Ñ„Ğ»Ğ¸ĞºÑ‚': conflict,
                'ĞŸĞ°Ñ€Ñ‹': ', '.join(set(data['pairs'])),
            })
        if coin_rows:
            st.dataframe(pd.DataFrame(coin_rows), use_container_width=True, hide_index=True)
        
        # === 4. RISK LIMITS CHECK ===
        st.markdown("#### âš ï¸ Ğ›Ğ¸Ğ¼Ğ¸Ñ‚Ñ‹ Ñ€Ğ¸ÑĞºĞ°")
        
        MAX_POSITIONS = 6
        MAX_COIN_EXPOSURE = 3  # max positions per coin
        MAX_CONCENTRATION_PCT = 40  # max % of portfolio in one coin
        
        lc1, lc2, lc3 = st.columns(3)
        
        with lc1:
            pos_ok = n_pos <= MAX_POSITIONS
            st.metric(
                "ĞŸĞ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¹", f"{n_pos}/{MAX_POSITIONS}",
                "âœ… OK" if pos_ok else "ğŸ”´ ĞŸĞ Ğ•Ğ’Ğ«Ğ¨Ğ•Ğ",
                delta_color="normal" if pos_ok else "inverse"
            )
        
        with lc2:
            max_c = max_coin[1]['total'] if sorted_coins else 0
            coin_ok = max_c <= MAX_COIN_EXPOSURE
            st.metric(
                f"ĞœĞ°ĞºÑ Ğ½Ğ° Ğ¼Ğ¾Ğ½ĞµÑ‚Ñƒ ({max_coin[0]})", f"{max_c}/{MAX_COIN_EXPOSURE}",
                "âœ… OK" if coin_ok else "ğŸ”´ ĞŸĞ Ğ•Ğ’Ğ«Ğ¨Ğ•Ğ",
                delta_color="normal" if coin_ok else "inverse"
            )
        
        with lc3:
            conc_ok = max_exposure_pct <= MAX_CONCENTRATION_PCT
            st.metric(
                "ĞšĞ¾Ğ½Ñ†ĞµĞ½Ñ‚Ñ€Ğ°Ñ†Ğ¸Ñ", f"{max_exposure_pct:.0f}%/{MAX_CONCENTRATION_PCT}%",
                "âœ… OK" if conc_ok else "ğŸ”´ ĞŸĞ Ğ•Ğ’Ğ«Ğ¨Ğ•ĞĞ",
                delta_color="normal" if conc_ok else "inverse"
            )
        
        # Warnings
        warnings_found = False
        for coin, data in sorted_coins:
            if data['total'] >= MAX_COIN_EXPOSURE:
                st.error(
                    f"ğŸš¨ **{coin}** Ğ² {data['total']} Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸ÑÑ… (Ğ»Ğ¸Ğ¼Ğ¸Ñ‚: {MAX_COIN_EXPOSURE}). "
                    f"ĞŸÑ€Ğ¸ Ğ¾Ğ±Ğ²Ğ°Ğ»Ğµ {coin} Ğ½Ğ° 10% Ğ’Ğ¡Ğ• {data['total']} Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾ÑÑ‚Ñ€Ğ°Ğ´Ğ°ÑÑ‚! "
                    f"**Ğ—Ğ°ĞºÑ€Ğ¾Ğ¹Ñ‚Ğµ {data['total'] - MAX_COIN_EXPOSURE + 1} Ğ½Ğ°Ğ¸Ğ¼ĞµĞ½ĞµĞµ Ğ¿Ñ€Ğ¸Ğ±Ñ‹Ğ»ÑŒĞ½ÑƒÑ.**")
                warnings_found = True
            elif data['total'] >= 2:
                st.warning(f"âš ï¸ **{coin}** Ğ² {data['total']} Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸ÑÑ… ({data['long']}L/{data['short']}S)")
                warnings_found = True
            
            if data['long'] > 0 and data['short'] > 0:
                st.error(
                    f"ğŸš¨ **{coin}** ĞšĞĞĞ¤Ğ›Ğ˜ĞšĞ¢: LONGÃ—{data['long']} + SHORTÃ—{data['short']} "
                    f"Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾ â†’ Ñ…ĞµĞ´Ğ¶Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ÑĞ°Ğ¼Ğ¾Ğ³Ğ¾ ÑĞµĞ±Ñ!")
                warnings_found = True
        
        if not warnings_found:
            st.success("âœ… ĞŸĞ¾Ñ€Ñ‚Ñ„ĞµĞ»ÑŒ Ğ² Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ°Ñ… Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ğ¾Ğ².")
        
        # === 5. Position P&L table ===
        st.markdown("#### ğŸ“ˆ P&L Ğ¿Ğ¾ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸ÑĞ¼")
        pnl_data = []
        for pos in open_positions:
            pair = f"{pos['coin1']}/{pos['coin2']}"
            mon = mon_cache.get(pos['id'])
            if mon:
                hours_in = pos.get('hours_in', 0)
                pnl_data.append({
                    '#': pos['id'],
                    'ĞŸĞ°Ñ€Ğ°': pair,
                    'Dir': pos['direction'],
                    'Entry Z': f"{mon['z_entry']:+.2f}",
                    'Now Z': f"{mon['z_now']:+.2f}",
                    'P&L': f"{mon['pnl_pct']:+.3f}%",
                    'Zâ†’0': 'âœ…' if mon['z_towards_zero'] else 'âŒ',
                    'Ğ§Ğ°ÑĞ¾Ğ²': f"{hours_in:.1f}",
                    'Ğ¡Ğ¸Ğ³Ğ½Ğ°Ğ»': (mon.get('exit_signal') or 'â€”')[:35],
                })
        if pnl_data:
            st.dataframe(pd.DataFrame(pnl_data), use_container_width=True, hide_index=True)
        
        # === 6. Quick recommendations ===
        st.markdown("#### ğŸ’¡ Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸")
        recs = []
        
        # Find worst position
        worst_pos = None
        worst_pnl = 0
        for pos in open_positions:
            mon = mon_cache.get(pos['id'])
            if mon and mon['pnl_pct'] < worst_pnl:
                worst_pnl = mon['pnl_pct']
                worst_pos = pos
        
        if worst_pos and worst_pnl < -0.5:
            recs.append(f"ğŸ”´ Ğ¥ÑƒĞ´ÑˆĞ°Ñ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ: **{worst_pos['coin1']}/{worst_pos['coin2']}** "
                       f"(P&L={worst_pnl:+.3f}%). Ğ Ğ°ÑÑĞ¼Ğ¾Ñ‚Ñ€Ğ¸Ñ‚Ğµ Ğ·Ğ°ĞºÑ€Ñ‹Ñ‚Ğ¸Ğµ.")
        
        # Exit signals
        exits = []
        for pos in open_positions:
            mon = mon_cache.get(pos['id'])
            if mon and mon.get('exit_signal'):
                exits.append(f"**{pos['coin1']}/{pos['coin2']}**: {mon['exit_signal'][:40]}")
        if exits:
            recs.append(f"ğŸ“ Ğ¡Ğ¸Ğ³Ğ½Ğ°Ğ»Ñ‹ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ°: " + "; ".join(exits))
        
        # Concentration
        for coin, data in sorted_coins:
            if data['total'] >= 3:
                # Find least profitable pair with this coin
                least_profit = None
                least_pnl = 999
                for pos in open_positions:
                    if pos['coin1'] == coin or pos['coin2'] == coin:
                        mon = mon_cache.get(pos['id'])
                        if mon and mon['pnl_pct'] < least_pnl:
                            least_pnl = mon['pnl_pct']
                            least_profit = pos
                if least_profit:
                    recs.append(
                        f"âš ï¸ Ğ”Ğ»Ñ ÑĞ½Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ ÑĞºÑĞ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ Ğ½Ğ° **{coin}** Ğ·Ğ°ĞºÑ€Ğ¾Ğ¹Ñ‚Ğµ "
                        f"**{least_profit['coin1']}/{least_profit['coin2']}** "
                        f"(Ğ½Ğ°Ğ¸Ğ¼ĞµĞ½ĞµĞµ Ğ¿Ñ€Ğ¸Ğ±Ñ‹Ğ»ÑŒĞ½Ğ°Ñ: {least_pnl:+.3f}%)")
        
        if recs:
            for r in recs:
                st.markdown(r)
        else:
            st.success("âœ… ĞĞµÑ‚ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¹. ĞŸĞ¾Ñ€Ñ‚Ñ„ĞµĞ»ÑŒ Ğ²Ñ‹Ğ³Ğ»ÑĞ´Ğ¸Ñ‚ Ğ·Ğ´Ğ¾Ñ€Ğ¾Ğ²Ñ‹Ğ¼.")
        
        # === 7. Portfolio Download ===
        st.markdown("#### ğŸ“¥ Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ğ¿Ğ¾Ñ€Ñ‚Ñ„ĞµĞ»Ñ")
        portfolio_rows = []
        for pos in open_positions:
            mon = mon_cache.get(pos['id'])
            portfolio_rows.append({
                '#': pos['id'],
                'ĞŸĞ°Ñ€Ğ°': f"{pos['coin1']}/{pos['coin2']}",
                'Dir': pos['direction'],
                'TF': pos.get('timeframe', '4h'),
                'Entry_Z': pos.get('entry_z', 0),
                'Current_Z': mon['z_now'] if mon else '',
                'Entry_HR': pos.get('entry_hr', 0),
                'Current_HR': mon['hr_now'] if mon else '',
                'HR_Drift_%': round(abs(mon['hr_now'] - pos.get('entry_hr', 0)) / max(0.0001, pos.get('entry_hr', 0)) * 100, 1) if mon else '',
                'P&L_%': round(mon['pnl_pct'], 4) if mon else '',
                'Hours_In': round(mon['hours_in'], 1) if mon else '',
                'HL_hours': round(mon.get('halflife_hours', 0), 1) if mon else '',
                'Hurst': round(mon.get('hurst', 0.5), 3) if mon else '',
                'P-value': round(mon.get('pvalue', 1.0), 4) if mon else '',
                'Z_Toward_Zero': mon.get('z_towards_zero', '') if mon else '',
                'Exit_Signal': (mon.get('exit_signal', '') or '')[:40] if mon else '',
                'Entry_Time': pos.get('entry_time', ''),
                'Entry_P1': pos.get('entry_price1', ''),
                'Entry_P2': pos.get('entry_price2', ''),
                'Now_P1': mon.get('price1_now', '') if mon else '',
                'Now_P2': mon.get('price2_now', '') if mon else '',
            })
        if portfolio_rows:
            portfolio_df = pd.DataFrame(portfolio_rows)
            csv_portfolio = portfolio_df.to_csv(index=False)
            
            dl1, dl2 = st.columns(2)
            with dl1:
                st.download_button("ğŸ“¥ ĞŸĞ¾Ñ€Ñ‚Ñ„ĞµĞ»ÑŒ (CSV)", csv_portfolio,
                    f"portfolio_{now_msk().strftime('%Y%m%d_%H%M')}.csv", "text/csv",
                    key="portfolio_csv_btn")
            with dl2:
                # Also auto-save to disk
                try:
                    import os
                    os.makedirs("position_exports", exist_ok=True)
                    pf_path = f"position_exports/portfolio_{now_msk().strftime('%Y%m%d_%H%M')}.csv"
                    portfolio_df.to_csv(pf_path, index=False)
                    st.caption(f"ğŸ’¾ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾: {pf_path}")
                except Exception:
                    pass

# Auto refresh
# v27: Non-blocking auto-refresh â€” rerun OUTSIDE try/except
_monitor_needs_rerun = False
if auto_refresh:
    _mon_wait = CFG('monitor', 'refresh_interval_sec', 120)
    st.info(f"â±ï¸ ĞĞ²Ñ‚Ğ¾-Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ñ‡ĞµÑ€ĞµĞ· {_mon_wait}Ñ...")
    time.sleep(_mon_wait)
    _monitor_needs_rerun = True

if _monitor_needs_rerun:
    st.rerun()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TAB 4: R8 Performance Tracker
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with tab4:
    st.markdown("### ğŸ“ˆ Performance Tracker (R8)")
    st.caption("ĞĞ°ĞºĞ¾Ğ¿Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¿Ğ¾ Ğ²ÑĞµĞ¼ Ğ·Ğ°ĞºÑ€Ñ‹Ñ‚Ñ‹Ğ¼ ÑĞ´ĞµĞ»ĞºĞ°Ğ¼")
    
    # Load history from persistent file + current session closed
    history = load_trade_history()
    
    # Also include closed positions from current session that might not be in history yet
    history_ids = {t.get('id', 0) for t in history}
    for cp in closed_positions:
        if cp.get('id', 0) not in history_ids:
            history.append({
                'id': cp.get('id', 0),
                'pair': f"{cp.get('coin1', '')}/{cp.get('coin2', '')}",
                'coin1': cp.get('coin1', ''), 'coin2': cp.get('coin2', ''),
                'direction': cp.get('direction', ''),
                'timeframe': cp.get('timeframe', '4h'),
                'entry_z': cp.get('entry_z', 0), 'exit_z': cp.get('exit_z', 0),
                'entry_hr': cp.get('entry_hr', 0), 'pnl_pct': cp.get('pnl_pct', 0),
                'entry_time': cp.get('entry_time', ''),
                'exit_time': cp.get('exit_time', ''),
                'exit_reason': cp.get('exit_reason', ''),
                'entry_price1': cp.get('entry_price1', 0),
                'entry_price2': cp.get('entry_price2', 0),
                'exit_price1': cp.get('exit_price1', 0),
                'exit_price2': cp.get('exit_price2', 0),
                'notes': cp.get('notes', ''),
                'best_pnl': cp.get('best_pnl', 0),
            })
    
    if not history:
        st.info("ğŸ“­ ĞĞµÑ‚ Ğ·Ğ°ĞºÑ€Ñ‹Ñ‚Ñ‹Ñ… ÑĞ´ĞµĞ»Ğ¾Ğº Ğ² Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸. Ğ—Ğ°ĞºÑ€Ğ¾Ğ¹Ñ‚Ğµ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ½Ğ°Ñ‡Ğ°Ñ‚ÑŒ Ğ½Ğ°ĞºĞ°Ğ¿Ğ»Ğ¸Ğ²Ğ°Ñ‚ÑŒ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ.")
        st.markdown("ğŸ’¡ **Ğ ÑƒÑ‡Ğ½Ğ¾Ğ¹ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚:** Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚Ğµ CSV Ñ Ğ¿Ñ€Ğ¾ÑˆĞ»Ñ‹Ğ¼Ğ¸ ÑĞ´ĞµĞ»ĞºĞ°Ğ¼Ğ¸.")
        
        uploaded_hist = st.file_uploader("ğŸ“¤ Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ (CSV)", type=['csv'], key='hist_import')
        if uploaded_hist:
            try:
                import io
                hist_df = pd.read_csv(io.StringIO(uploaded_hist.getvalue().decode()))
                st.dataframe(hist_df)
                
                if st.button("âœ… Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑÑ‚Ğ¸ ÑĞ´ĞµĞ»ĞºĞ¸"):
                    for _, row in hist_df.iterrows():
                        trade = {
                            'id': int(row.get('#', row.get('id', 0))),
                            'coin1': str(row.get('ĞŸĞ°Ñ€Ğ°', '')).split('/')[0] if '/' in str(row.get('ĞŸĞ°Ñ€Ğ°', '')) else '',
                            'coin2': str(row.get('ĞŸĞ°Ñ€Ğ°', '')).split('/')[1] if '/' in str(row.get('ĞŸĞ°Ñ€Ğ°', '')) else '',
                            'direction': row.get('Dir', row.get('direction', '')),
                            'timeframe': row.get('TF', row.get('timeframe', '4h')),
                            'entry_z': float(str(row.get('Entry Z', row.get('entry_z', 0))).replace('+', '')),
                            'exit_z': float(str(row.get('Exit Z', row.get('exit_z', 0))).replace('+', '')),
                            'entry_hr': float(row.get('entry_hr', 1.0)),
                            'pnl_pct': float(str(row.get('P&L %', row.get('pnl_pct', 0))).replace('+', '').replace('%', '')),
                            'entry_time': str(row.get('Ğ’Ñ…Ğ¾Ğ´', row.get('entry_time', ''))),
                            'exit_time': str(row.get('Ğ’Ñ‹Ñ…Ğ¾Ğ´', row.get('exit_time', ''))),
                            'exit_reason': str(row.get('ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ°', row.get('exit_reason', 'MANUAL'))),
                            'notes': '',
                            'best_pnl': 0,
                            'entry_price1': 0, 'entry_price2': 0,
                            'exit_price1': 0, 'exit_price2': 0,
                        }
                        save_trade_to_history(trade)
                    st.success(f"âœ… Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ {len(hist_df)} ÑĞ´ĞµĞ»Ğ¾Ğº!")
                    st.rerun()
            except Exception as ex:
                st.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ°: {ex}")
    else:
        # === DASHBOARD ===
        pnls = [float(t.get('pnl_pct', 0)) for t in history]
        n_trades = len(history)
        total_pnl = sum(pnls)
        winners = sum(1 for p in pnls if p > 0)
        losers = sum(1 for p in pnls if p < 0)
        win_rate = winners / n_trades * 100 if n_trades > 0 else 0
        avg_pnl = total_pnl / n_trades if n_trades > 0 else 0
        avg_win = np.mean([p for p in pnls if p > 0]) if winners > 0 else 0
        avg_loss = np.mean([p for p in pnls if p < 0]) if losers > 0 else 0
        pf = abs(sum(p for p in pnls if p > 0) / sum(p for p in pnls if p < 0)) if losers > 0 and sum(p for p in pnls if p < 0) != 0 else float('inf')
        
        # Max drawdown
        cumulative = np.cumsum(pnls)
        peak = np.maximum.accumulate(cumulative)
        drawdown = cumulative - peak
        max_dd = min(drawdown) if len(drawdown) > 0 else 0
        
        # Metrics row 1
        m1, m2, m3, m4, m5 = st.columns(5)
        m1.metric("Ğ’ÑĞµĞ³Ğ¾ ÑĞ´ĞµĞ»Ğ¾Ğº", n_trades)
        m2.metric("Ğ¡ÑƒĞ¼Ğ¼Ğ°Ñ€Ğ½Ñ‹Ğ¹ P&L", f"{total_pnl:+.2f}%",
                 delta=f"{total_pnl:+.2f}%", delta_color="normal")
        m3.metric("Win Rate", f"{win_rate:.0f}%",
                 delta=f"{winners}W / {losers}L")
        m4.metric("Avg P&L", f"{avg_pnl:+.3f}%")
        m5.metric("Profit Factor", f"{pf:.2f}" if pf < 100 else "âˆ")
        
        # Metrics row 2
        m6, m7, m8, m9 = st.columns(4)
        m6.metric("Avg Win", f"{avg_win:+.3f}%")
        m7.metric("Avg Loss", f"{avg_loss:+.3f}%")
        m8.metric("Max Drawdown", f"{max_dd:+.2f}%")
        
        # Best streak
        streaks = []
        current_streak = 0
        for p in pnls:
            if p > 0:
                current_streak += 1
            else:
                if current_streak > 0:
                    streaks.append(current_streak)
                current_streak = 0
        if current_streak > 0:
            streaks.append(current_streak)
        best_streak = max(streaks) if streaks else 0
        m9.metric("Best Win Streak", f"{best_streak}")
        
        # === EQUITY CURVE ===
        st.markdown("#### ğŸ“ˆ Equity Curve")
        import plotly.graph_objects as go
        
        cum_pnl = list(np.cumsum(pnls))
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            y=[0] + cum_pnl,
            mode='lines+markers',
            name='Cumulative P&L',
            line=dict(color='#00c853', width=2),
            marker=dict(size=5, color=['green' if p > 0 else 'red' for p in [0] + list(pnls)])
        ))
        fig.update_layout(
            height=300, margin=dict(l=0, r=0, t=30, b=0),
            yaxis_title="Cumulative P&L %",
            xaxis_title="Trade #",
            template="plotly_dark"
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # === BY PAIR ANALYSIS ===
        st.markdown("#### ğŸª™ Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¿Ğ¾ Ğ¿Ğ°Ñ€Ğ°Ğ¼")
        pair_stats = {}
        for t in history:
            pair = t.get('pair', f"{t.get('coin1','')}/{t.get('coin2','')}")
            if pair not in pair_stats:
                pair_stats[pair] = {'pnls': [], 'count': 0}
            pair_stats[pair]['pnls'].append(float(t.get('pnl_pct', 0)))
            pair_stats[pair]['count'] += 1
        
        pair_rows = []
        for pair, stats in sorted(pair_stats.items(), key=lambda x: sum(x[1]['pnls']), reverse=True):
            ppnls = stats['pnls']
            pair_rows.append({
                'ĞŸĞ°Ñ€Ğ°': pair,
                'Ğ¡Ğ´ĞµĞ»Ğ¾Ğº': stats['count'],
                'Total P&L': f"{sum(ppnls):+.2f}%",
                'Avg P&L': f"{np.mean(ppnls):+.3f}%",
                'WR': f"{sum(1 for p in ppnls if p > 0)/len(ppnls)*100:.0f}%",
                'Best': f"{max(ppnls):+.2f}%",
                'Worst': f"{min(ppnls):+.2f}%",
            })
        if pair_rows:
            st.dataframe(pd.DataFrame(pair_rows), use_container_width=True, hide_index=True)
        
        # === BY DAY ANALYSIS ===
        st.markdown("#### ğŸ“… Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¿Ğ¾ Ğ´Ğ½ÑĞ¼")
        day_stats = {}
        for t in history:
            day = str(t.get('exit_time', t.get('entry_time', '')))[:10]
            if day and day != 'None':
                if day not in day_stats:
                    day_stats[day] = {'pnls': [], 'count': 0}
                day_stats[day]['pnls'].append(float(t.get('pnl_pct', 0)))
                day_stats[day]['count'] += 1
        
        day_rows = []
        for day, stats in sorted(day_stats.items()):
            dpnls = stats['pnls']
            day_rows.append({
                'Ğ”Ğ°Ñ‚Ğ°': day,
                'Ğ¡Ğ´ĞµĞ»Ğ¾Ğº': stats['count'],
                'Total P&L': f"{sum(dpnls):+.2f}%",
                'WR': f"{sum(1 for p in dpnls if p > 0)/len(dpnls)*100:.0f}%",
                'Avg P&L': f"{np.mean(dpnls):+.3f}%",
            })
        if day_rows:
            st.dataframe(pd.DataFrame(day_rows), use_container_width=True, hide_index=True)
        
        # === TRADES TABLE ===
        st.markdown("#### ğŸ“‹ Ğ’ÑĞµ ÑĞ´ĞµĞ»ĞºĞ¸")
        trade_rows = []
        for t in reversed(history):
            trade_rows.append({
                '#': t.get('id', ''),
                'ĞŸĞ°Ñ€Ğ°': t.get('pair', ''),
                'Dir': t.get('direction', ''),
                'Entry Z': f"{float(t.get('entry_z', 0)):+.2f}",
                'Exit Z': f"{float(t.get('exit_z', 0)):+.2f}",
                'P&L': f"{float(t.get('pnl_pct', 0)):+.2f}%",
                'ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ°': t.get('exit_reason', ''),
                'Ğ’Ñ…Ğ¾Ğ´': str(t.get('entry_time', ''))[-5:],
                'Ğ’Ñ‹Ñ…Ğ¾Ğ´': str(t.get('exit_time', ''))[-5:],
            })
        if trade_rows:
            st.dataframe(pd.DataFrame(trade_rows), use_container_width=True, hide_index=True)
        
        # === EXPORT ===
        st.markdown("#### ğŸ“¥ Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚")
        hist_df = pd.DataFrame(history)
        csv_hist = hist_df.to_csv(index=False)
        st.download_button("ğŸ“¥ Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ğ»Ğ½ÑƒÑ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ (CSV)", csv_hist,
                          f"trade_history_{now_msk().strftime('%Y%m%d_%H%M')}.csv",
                          "text/csv", key="hist_export_btn")

st.divider()
st.caption("""
ĞšĞ°Ğº Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ:
1. ĞĞ°Ğ¹Ğ´Ğ¸ ğŸŸ¢ Ğ’Ğ¥ĞĞ” Ğ² ÑĞºÑ€Ğ¸Ğ½ĞµÑ€Ğµ
2. Ğ¡ĞºĞ¾Ğ¿Ğ¸Ñ€ÑƒĞ¹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ: Coin1, Coin2, Direction, Z, HR, Ñ†ĞµĞ½Ñ‹
3. Ğ’Ğ²ĞµĞ´Ğ¸ Ğ² Ñ„Ğ¾Ñ€Ğ¼Ñƒ ÑĞ»ĞµĞ²Ğ° â†’ "Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ñ†ĞµĞ½Ñ‹ + Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ"
4. ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€ Ğ¿Ğ¾ĞºĞ°Ğ¶ĞµÑ‚ ĞºĞ¾Ğ³Ğ´Ğ° Ğ·Ğ°ĞºÑ€Ñ‹Ğ²Ğ°Ñ‚ÑŒ + Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ´Ğ¸Ñ‚ ĞµÑĞ»Ğ¸ Ğ¿Ğ°Ñ€Ğ° Ğ¿Ğ¾Ñ‚ĞµÑ€ÑĞ»Ğ° ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾
""")
